{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40059,"status":"ok","timestamp":1758510985444,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"toY_hSXlMvyp","outputId":"93d68d13-294a-41ec-9cc1-478e88e102f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: faker in /usr/local/lib/python3.12/dist-packages (37.8.0)\n","Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from faker) (2025.2)\n","‚úì All dependencies installed successfully\n","‚úì Environment configured for optimal display\n"]}],"source":["# Install required packages with specific versions for compatibility\n","!pip install sdv>=1.0.0 pandas numpy networkx scikit-learn matplotlib seaborn plotly\n","!pip install faker  # For realistic fake data generation\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Set pandas display options for better readability\n","import pandas as pd\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', None)\n","pd.set_option('display.max_colwidth', 50)\n","\n","print(\"‚úì All dependencies installed successfully\")\n","print(\"‚úì Environment configured for optimal display\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23598,"status":"ok","timestamp":1758511013456,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"Z6saosTPNHEA","outputId":"4b5d6ab2-c030-4110-d821-7fafaa0d91b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì All libraries imported successfully\n","‚úì Faker initialized with seed 42 for reproducible results\n","‚úì NumPy random seed set to 42\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from datetime import datetime, timedelta\n","import random\n","from faker import Faker\n","\n","# SDV imports for multi-table synthesis\n","from sdv.metadata import Metadata\n","from sdv.multi_table import HMASynthesizer\n","\n","# SDV evaluation imports - CRITICAL for quality assessment\n","from sdv.evaluation.multi_table import run_diagnostic, evaluate_quality\n","\n","# Additional SDV utilities\n","from sdv.datasets.demo import download_demo\n","\n","# NetworkX for relationship analysis\n","import networkx as nx\n","from typing import Dict, List, Tuple, Optional, Any\n","\n","# Initialize Faker for realistic data generation\n","fake = Faker(['en_US', 'en_GB', 'es_ES', 'fr_FR'])  # Multi-locale support\n","Faker.seed(42)  # Reproducible fake data\n","np.random.seed(42)  # Reproducible random numbers\n","\n","print(\"‚úì All libraries imported successfully\")\n","print(f\"‚úì Faker initialized with seed 42 for reproducible results\")\n","print(f\"‚úì NumPy random seed set to 42\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":138,"status":"ok","timestamp":1758511019441,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"r1-g6q2rNInh","outputId":"d493db1a-24a8-493e-9e69-cb851f7d5afb"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Enhanced RecursiveMultiTableSynthesizer class (Part 1) defined\n"]}],"source":["class RecursiveMultiTableSynthesizer:\n","    \"\"\"\n","    FIXED: Advanced multi-table synthetic data generator with automatic relationship detection,\n","    comprehensive evaluation metrics, and support for complex enterprise data structures.\n","\n","    Features:\n","    - Proper metadata initialization (FIXES AttributeError)\n","    - Support for 20+ interconnected tables\n","    - Recursive and self-referencing relationships\n","    - Comprehensive quality evaluation\n","    - Advanced visualization capabilities\n","    \"\"\"\n","\n","    def __init__(self, synthesizer_type='gaussian_copula'):\n","        \"\"\"\n","        FIXED: Initialize the enhanced recursive multi-table synthesizer with proper metadata.\n","\n","        Args:\n","            synthesizer_type (str): Type of synthesizer ('gaussian_copula' or 'ctgan')\n","        \"\"\"\n","        self.synthesizer_type = synthesizer_type\n","        self.metadata = Metadata()  # FIXED: Properly initialize Metadata object instead of None\n","        self.synthesizer = None\n","        self.real_data = {}\n","        self.synthetic_data = {}\n","\n","        # Enhanced tracking\n","        self.table_relationships = {}\n","        self.dependency_graph = nx.DiGraph()\n","        self.table_stats = {}\n","        self.generation_stats = {}\n","\n","        # Evaluation results storage\n","        self.diagnostic_report = None\n","        self.quality_report = None\n","        self.evaluation_scores = {}\n","\n","        print(f\"Enhanced RecursiveMultiTableSynthesizer initialized with {synthesizer_type}\")\n","        print(\"Ready for automatic relationship detection and quality evaluation\")\n","\n","    def add_table_data(self, table_name: str, data: pd.DataFrame,\n","                      primary_key: Optional[str] = None):\n","        \"\"\"\n","        FIXED: Add a single table to the multi-table structure with proper error handling.\n","\n","        Args:\n","            table_name (str): Name of the table\n","            data (pd.DataFrame): The actual data\n","            primary_key (str): Primary key column name\n","        \"\"\"\n","        try:\n","            self.real_data[table_name] = data.copy()\n","\n","            # Add table to metadata using the correct method\n","            self.metadata.detect_table_from_dataframe(table_name=table_name, data=data)\n","\n","            # Set primary key if provided\n","            if primary_key and primary_key in data.columns:\n","                try:\n","                    # Mark the PK column as an id sdtype\n","                    self.metadata.update_column(\n","                        table_name=table_name,\n","                        column_name=primary_key,\n","                        sdtype='id'\n","                    )\n","\n","                    # Set the PK\n","                    self.metadata.set_primary_key(\n","                        table_name=table_name,\n","                        column_name=primary_key\n","                    )\n","                    print(f\"Added table '{table_name}' with primary key '{primary_key}'\")\n","                except Exception as e:\n","                    print(f\"Warning setting primary key for {table_name}: {e}\")\n","            else:\n","                print(f\"Added table '{table_name}' (no primary key specified)\")\n","\n","        except Exception as e:\n","            print(f\"Error adding table {table_name}: {e}\")\n","            raise\n","\n","    def add_tables_from_dict(self, data_dict: Dict[str, pd.DataFrame],\n","                           primary_keys: Optional[Dict[str, str]] = None):\n","        \"\"\"\n","        FIXED: Add multiple tables at once with proper metadata handling.\n","\n","        Args:\n","            data_dict: Dictionary of {table_name: DataFrame}\n","            primary_keys: Dictionary of {table_name: primary_key_column}\n","        \"\"\"\n","        print(f\"\\n=== ADDING {len(data_dict)} TABLES WITH METADATA DETECTION ===\")\n","\n","        # Store all data\n","        self.real_data = data_dict.copy()\n","\n","        # Add each table individually with proper primary key handling\n","        print(\"Adding tables with individual metadata detection...\")\n","        for table_name, df in data_dict.items():\n","            pk = primary_keys.get(table_name) if primary_keys else None\n","            self.add_table_data(table_name, df, pk)\n","\n","        # Generate comprehensive statistics\n","        self._generate_table_statistics()\n","\n","        print(f\"Successfully added {len(data_dict)} tables with metadata\")\n","\n","    def _generate_table_statistics(self):\n","        \"\"\"Generate comprehensive statistics for all tables.\"\"\"\n","        print(\"\\nGenerating comprehensive table statistics...\")\n","\n","        for table_name, df in self.real_data.items():\n","            stats = {\n","                'rows': len(df),\n","                'columns': len(df.columns),\n","                'numeric_cols': len(df.select_dtypes(include=[np.number]).columns),\n","                'categorical_cols': len(df.select_dtypes(include=['object', 'category']).columns),\n","                'datetime_cols': len(df.select_dtypes(include=['datetime64']).columns),\n","                'missing_values': df.isnull().sum().sum(),\n","                'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024 / 1024\n","            }\n","            self.table_stats[table_name] = stats\n","\n","        total_rows = sum(stats['rows'] for stats in self.table_stats.values())\n","        total_memory = sum(stats['memory_usage_mb'] for stats in self.table_stats.values())\n","\n","        print(f\"   Total rows across all tables: {total_rows:,}\")\n","        print(f\"   Total memory usage: {total_memory:.2f} MB\")\n","        print(\"Table statistics generated successfully\")\n","\n","print(\"‚úì Enhanced RecursiveMultiTableSynthesizer class (Part 1) defined\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1758511026616,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"2wNsDHq7NIqX","outputId":"3072dbf5-7a4e-4b01-f4df-4c7c510f5e7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Enhanced relationship management methods added to class\n"]}],"source":["def add_custom_relationship(self, parent_table: str, parent_column: str,\n","                          child_table: str, child_column: str):\n","    \"\"\"\n","    Manually add a relationship that wasn't auto-detected.\n","\n","    Args:\n","        parent_table: Name of the parent table\n","        parent_column: Primary key column in parent table\n","        child_table: Name of the child table\n","        child_column: Foreign key column in child table\n","    \"\"\"\n","    try:\n","        # Validate tables and columns exist\n","        if parent_table not in self.real_data:\n","            raise ValueError(f\"Parent table '{parent_table}' not found\")\n","        if child_table not in self.real_data:\n","            raise ValueError(f\"Child table '{child_table}' not found\")\n","        if parent_column not in self.real_data[parent_table].columns:\n","            raise ValueError(f\"Column '{parent_column}' not found in '{parent_table}'\")\n","        if child_column not in self.real_data[child_table].columns:\n","            raise ValueError(f\"Column '{child_column}' not found in '{child_table}'\")\n","\n","        print(\"====> parent_table_name :  \", parent_table)\n","        print(\"====> parent_primary_key :  \", parent_column)\n","        print(\"====> child_table_name :  \", child_table)\n","        print(\"====> child_foreign_key :  \", child_column)\n","\n","        # Update metadata - mark foreign key column as 'id' type\n","        self.metadata.update_column(child_table, child_column, sdtype='id')\n","\n","        #====> parent_table_name :   companies\n","        #====> parent_primary_key :   company_id\n","        #====> child_table_name :   departments\n","        #====> child_foreign_key :   company_id\n","        #‚ùå Error adding relationship: Unknown table name ('company_id').\n","\n","        #mData = synthesizer.metadata\n","\n","        #mData.add_relationship(\n","        #parent_table_name='companies',\n","        #child_table_name='departments',\n","        #parent_primary_key='company_id',\n","        #child_foreign_key='company_id'\n","        #)\n","\n","        # Add relationship to metadata\n","        self.metadata.add_relationship(\n","            parent_table_name=parent_table,\n","            parent_primary_key=parent_column,\n","            child_table_name=child_table,\n","            child_foreign_key=child_column\n","        )\n","\n","        # Update dependency graph\n","        self.dependency_graph.add_edge(parent_table, child_table)\n","\n","        # Store relationship info for tracking\n","        if child_table not in self.table_relationships:\n","            self.table_relationships[child_table] = {}\n","        self.table_relationships[child_table][child_column] = parent_table\n","\n","        print(f\"‚úÖ Added custom relationship: {parent_table}.{parent_column} ‚Üí {child_table}.{child_column}\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå Error adding relationship: {e}\")\n","\n","def analyze_relationships(self):\n","    \"\"\"\n","    Analyze and visualize the relationship structure.\n","\n","    Returns:\n","        Dict containing relationship analysis results\n","    \"\"\"\n","    print(\"\\nüîç ANALYZING RELATIONSHIP STRUCTURE\")\n","    print(\"=\" * 50)\n","\n","    # Get relationships from metadata\n","    relationships = []\n","    try:\n","        metadata_dict = self.metadata.to_dict()\n","        relationships = metadata_dict.get('relationships', [])\n","\n","        print(f\"üìä Total relationships detected: {len(relationships)}\")\n","\n","        # Analyze relationship types\n","        self_referencing = []\n","        hierarchical = []\n","        many_to_many = []\n","\n","        for rel in relationships:\n","            parent_table = rel.get('parent_table_name')\n","            child_table = rel.get('child_table_name')\n","\n","            if parent_table == child_table:\n","                self_referencing.append(rel)\n","            else:\n","                hierarchical.append(rel)\n","\n","        print(f\"üîÑ Self-referencing relationships: {len(self_referencing)}\")\n","        print(f\"üå≥ Hierarchical relationships: {len(hierarchical)}\")\n","\n","        # Display relationship details\n","        if hierarchical:\n","            print(\"\\nüìã HIERARCHICAL RELATIONSHIPS:\")\n","            for rel in hierarchical[:10]:  # Show first 10\n","                parent = rel.get('parent_table_name')\n","                child = rel.get('child_table_name')\n","                parent_key = rel.get('parent_primary_key')\n","                child_key = rel.get('child_foreign_key')\n","                print(f\"   {parent}.{parent_key} ‚Üí {child}.{child_key}\")\n","\n","        if self_referencing:\n","            print(\"\\nüîÑ SELF-REFERENCING RELATIONSHIPS:\")\n","            for rel in self_referencing:\n","                table = rel.get('parent_table_name')\n","                parent_key = rel.get('parent_primary_key')\n","                child_key = rel.get('child_foreign_key')\n","                print(f\"   {table}.{parent_key} ‚Üê {table}.{child_key}\")\n","\n","        return {\n","            'total_relationships': len(relationships),\n","            'hierarchical': len(hierarchical),\n","            'self_referencing': len(self_referencing),\n","            'relationship_details': relationships\n","        }\n","\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Error analyzing relationships: {e}\")\n","        return {'error': str(e)}\n","\n","def visualize_table_dependencies(self, figsize=(15, 10)):\n","    \"\"\"\n","    Create a visualization of table dependencies and relationships.\n","\n","    Args:\n","        figsize: Figure size for the visualization\n","    \"\"\"\n","    print(\"\\nüé® Creating relationship visualization...\")\n","\n","    try:\n","        # Create graph from relationships\n","        G = nx.DiGraph()\n","\n","        # Add all tables as nodes\n","        for table_name in self.real_data.keys():\n","            node_size = self.table_stats[table_name]['rows']\n","            G.add_node(table_name, size=node_size)\n","\n","        # Add edges from relationships\n","        metadata_dict = self.metadata.to_dict()\n","        relationships = metadata_dict.get('relationships', [])\n","\n","        for rel in relationships:\n","            parent = rel.get('parent_table_name')\n","            child = rel.get('child_table_name')\n","            if parent and child:\n","                G.add_edge(parent, child)\n","\n","        # Create visualization\n","        plt.figure(figsize=figsize)\n","\n","        # Use spring layout for better visualization\n","        pos = nx.spring_layout(G, k=3, iterations=50)\n","\n","        # Calculate node sizes based on table row counts\n","        node_sizes = [self.table_stats[node]['rows'] / 10 for node in G.nodes()]\n","\n","        # Draw the graph\n","        nx.draw(G, pos,\n","                with_labels=True,\n","                node_color='lightblue',\n","                node_size=node_sizes,\n","                font_size=8,\n","                font_weight='bold',\n","                arrows=True,\n","                arrowsize=20,\n","                edge_color='gray',\n","                alpha=0.7)\n","\n","        plt.title(\"Table Relationship Dependencies\\n(Node size reflects table size)\",\n","                 fontsize=16, fontweight='bold')\n","        plt.axis('off')\n","        plt.tight_layout()\n","        plt.show()\n","\n","        print(\"‚úÖ Dependency visualization created successfully\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå Error creating visualization: {e}\")\n","\n","# Add methods to the class\n","RecursiveMultiTableSynthesizer.add_custom_relationship = add_custom_relationship\n","RecursiveMultiTableSynthesizer.analyze_relationships = analyze_relationships\n","RecursiveMultiTableSynthesizer.visualize_table_dependencies = visualize_table_dependencies\n","\n","print(\"‚úì Enhanced relationship management methods added to class\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61,"status":"ok","timestamp":1758511033615,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"l8euOoT1NIs6","outputId":"ffe5eb91-e0ca-4127-ed39-77f60fef93d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Training and generation methods added to class\n"]}],"source":["def train_synthesizer(self, verbose=True):\n","    \"\"\"\n","    Train the multi-table synthesizer with comprehensive logging.\n","\n","    Args:\n","        verbose: Whether to show detailed training progress\n","    \"\"\"\n","    print(\"\\nüöÄ TRAINING MULTI-TABLE SYNTHESIZER\")\n","    print(\"=\" * 50)\n","\n","    try:\n","        # Validate metadata first\n","        print(\"üîç Validating metadata structure...\")\n","        self.metadata.validate()\n","        print(\"‚úÖ Metadata validation successful\")\n","\n","        # Initialize synthesizer\n","        print(f\"ü§ñ Initializing {self.synthesizer_type} synthesizer...\")\n","        self.synthesizer = HMASynthesizer(metadata=self.metadata)\n","        print(\"‚úÖ Synthesizer initialized successfully\")\n","\n","        # Training phase\n","        print(\"üìö Starting training process...\")\n","        if verbose:\n","            print(f\"   üìä Training on {len(self.real_data)} tables\")\n","            print(f\"   üìà Total data points: {sum(len(df) for df in self.real_data.values()):,}\")\n","\n","        # Record training start time\n","        training_start = datetime.now()\n","\n","        # Train the model\n","        self.synthesizer.fit(self.real_data)\n","\n","        # Record training completion\n","        training_end = datetime.now()\n","        training_duration = training_end - training_start\n","\n","        # Store training statistics\n","        self.generation_stats['training_duration'] = training_duration.total_seconds()\n","        self.generation_stats['training_start'] = training_start\n","        self.generation_stats['training_end'] = training_end\n","\n","        print(f\"‚úÖ Training completed successfully!\")\n","        print(f\"‚è±Ô∏è  Training duration: {training_duration}\")\n","\n","        return True\n","\n","    except Exception as e:\n","        print(f\"‚ùå Training failed: {e}\")\n","        print(\"üí° Check your data structure and relationships\")\n","        return False\n","\n","def generate_synthetic_data(self, scale: float = 1.0,\n","                          custom_table_sizes: Optional[Dict[str, int]] = None,\n","                          verbose: bool = True):\n","    \"\"\"\n","    Generate synthetic data with advanced options and monitoring.\n","\n","    Args:\n","        scale: Scaling factor for data generation (1.0 = same size as original)\n","        custom_table_sizes: Dictionary specifying exact sizes for specific tables\n","        verbose: Whether to show detailed generation progress\n","\n","    Returns:\n","        Dictionary containing synthetic DataFrames\n","    \"\"\"\n","    print(f\"\\n‚ö° GENERATING SYNTHETIC DATA (Scale: {scale}x)\")\n","    print(\"=\" * 50)\n","\n","    if not self.synthesizer:\n","        print(\"‚ùå Synthesizer not trained. Please call train_synthesizer() first.\")\n","        return None\n","\n","    try:\n","        generation_start = datetime.now()\n","\n","        if verbose:\n","            print(\"üéØ Generation parameters:\")\n","            if custom_table_sizes:\n","                print(\"   üìã Using custom table sizes:\")\n","                for table, size in custom_table_sizes.items():\n","                    original_size = len(self.real_data.get(table, []))\n","                    ratio = size / original_size if original_size > 0 else 0\n","                    print(f\"      {table}: {size:,} rows ({ratio:.2f}x original)\")\n","            else:\n","                print(f\"   üìà Using scale factor: {scale}x\")\n","\n","        # Generate synthetic data\n","        print(\"üîÑ Generating synthetic tables...\")\n","\n","        if custom_table_sizes:\n","            # Convert custom sizes to scale and generate\n","            total_original = sum(len(df) for df in self.real_data.values())\n","            total_custom = sum(custom_table_sizes.get(table, len(df))\n","                             for table, df in self.real_data.items())\n","            effective_scale = total_custom / total_original if total_original > 0 else 1.0\n","\n","            print(f\"   üìä Effective scale from custom sizes: {effective_scale:.2f}x\")\n","            self.synthetic_data = self.synthesizer.sample(scale=effective_scale)\n","\n","            # Trim to exact requested sizes\n","            for table_name, requested_size in custom_table_sizes.items():\n","                if table_name in self.synthetic_data:\n","                    current_size = len(self.synthetic_data[table_name])\n","                    if current_size > requested_size:\n","                        self.synthetic_data[table_name] = self.synthetic_data[table_name].head(requested_size)\n","                        if verbose:\n","                            print(f\"   ‚úÇÔ∏è  Trimmed {table_name}: {current_size} ‚Üí {requested_size} rows\")\n","        else:\n","            self.synthetic_data = self.synthesizer.sample(scale=scale)\n","\n","        generation_end = datetime.now()\n","        generation_duration = generation_end - generation_start\n","\n","        # Store generation statistics\n","        self.generation_stats['generation_duration'] = generation_duration.total_seconds()\n","        self.generation_stats['generation_start'] = generation_start\n","        self.generation_stats['generation_end'] = generation_end\n","        self.generation_stats['scale_used'] = scale\n","\n","        # Summary statistics\n","        print(\"‚úÖ Synthetic data generation completed!\")\n","        print(f\"‚è±Ô∏è  Generation duration: {generation_duration}\")\n","        print(\"\\nüìä GENERATION SUMMARY:\")\n","\n","        for table_name, synthetic_df in self.synthetic_data.items():\n","            original_size = len(self.real_data[table_name])\n","            synthetic_size = len(synthetic_df)\n","            actual_ratio = synthetic_size / original_size if original_size > 0 else 0\n","\n","            print(f\"   {table_name:20} | Original: {original_size:6,} | Synthetic: {synthetic_size:6,} | Ratio: {actual_ratio:.2f}x\")\n","\n","        return self.synthetic_data\n","\n","    except Exception as e:\n","        print(f\"‚ùå Generation failed: {e}\")\n","        print(\"üí° Try reducing the scale factor or checking your trained model\")\n","        return None\n","\n","# Add methods to the class\n","RecursiveMultiTableSynthesizer.train_synthesizer = train_synthesizer\n","RecursiveMultiTableSynthesizer.generate_synthetic_data = generate_synthetic_data\n","\n","print(\"‚úì Training and generation methods added to class\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1758511040989,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"KR-Aj7iSNIvR","outputId":"8eb24ea4-8617-4be4-ab6e-a4304d089111"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Advanced evaluation methods added to class\n","‚úÖ RecursiveMultiTableSynthesizer class is now complete with all advanced features!\n"]}],"source":["def run_diagnostic_evaluation(self, verbose: bool = True):\n","    \"\"\"\n","    Run comprehensive diagnostic evaluation using SDV's diagnostic framework.\n","\n","    Args:\n","        verbose: Whether to show detailed diagnostic results\n","\n","    Returns:\n","        Diagnostic report with data validity and synthesis quality metrics\n","    \"\"\"\n","    print(\"\\nüîç RUNNING DIAGNOSTIC EVALUATION\")\n","    print(\"=\" * 50)\n","\n","    if not self.synthetic_data:\n","        print(\"‚ùå No synthetic data available. Generate synthetic data first.\")\n","        return None\n","\n","    try:\n","        print(\"üî¨ Running SDV diagnostic evaluation...\")\n","        diagnostic_start = datetime.now()\n","\n","        # Run comprehensive diagnostic\n","        self.diagnostic_report = run_diagnostic(\n","            real_data=self.real_data,\n","            synthetic_data=self.synthetic_data,\n","            metadata=self.metadata,\n","            verbose=verbose\n","        )\n","\n","        diagnostic_end = datetime.now()\n","        diagnostic_duration = diagnostic_end - diagnostic_start\n","\n","        print(f\"‚úÖ Diagnostic evaluation completed in {diagnostic_duration}\")\n","\n","        # Extract key metrics\n","        if hasattr(self.diagnostic_report, 'get_results'):\n","            results = self.diagnostic_report.get_results()\n","\n","            print(\"\\nüìä DIAGNOSTIC SUMMARY:\")\n","            print(f\"   üéØ Overall Quality Score: {results.get('Quality Score', 'N/A')}\")\n","            print(f\"   üîó Relationship Validity: {results.get('Relationship Validity', 'N/A')}\")\n","            print(f\"   üìà Data Validity: {results.get('Data Validity', 'N/A')}\")\n","\n","            # Store evaluation scores\n","            self.evaluation_scores['diagnostic'] = results\n","\n","        return self.diagnostic_report\n","\n","    except Exception as e:\n","        print(f\"‚ùå Diagnostic evaluation failed: {e}\")\n","        return None\n","\n","def run_quality_evaluation(self, verbose: bool = True):\n","    \"\"\"\n","    Run comprehensive quality evaluation using SDV's quality framework.\n","\n","    Args:\n","        verbose: Whether to show detailed quality results\n","\n","    Returns:\n","        Quality report with statistical similarity metrics\n","    \"\"\"\n","    print(\"\\nüìä RUNNING QUALITY EVALUATION\")\n","    print(\"=\" * 50)\n","\n","    if not self.synthetic_data:\n","        print(\"‚ùå No synthetic data available. Generate synthetic data first.\")\n","        return None\n","\n","    try:\n","        print(\"üìà Running SDV quality evaluation...\")\n","        quality_start = datetime.now()\n","\n","        # Run comprehensive quality evaluation\n","        self.quality_report = evaluate_quality(\n","            real_data=self.real_data,\n","            synthetic_data=self.synthetic_data,\n","            metadata=self.metadata,\n","            verbose=verbose\n","        )\n","\n","        quality_end = datetime.now()\n","        quality_duration = quality_end - quality_start\n","\n","        print(f\"‚úÖ Quality evaluation completed in {quality_duration}\")\n","\n","        # Extract key metrics\n","        if hasattr(self.quality_report, 'get_results'):\n","            results = self.quality_report.get_results()\n","\n","            print(\"\\nüìä QUALITY SUMMARY:\")\n","            for metric_name, score in results.items():\n","                if isinstance(score, (int, float)):\n","                    print(f\"   üìä {metric_name}: {score:.3f}\")\n","                else:\n","                    print(f\"   üìä {metric_name}: {score}\")\n","\n","            # Store evaluation scores\n","            self.evaluation_scores['quality'] = results\n","\n","        return self.quality_report\n","\n","    except Exception as e:\n","        print(f\"‚ùå Quality evaluation failed: {e}\")\n","        return None\n","\n","def generate_evaluation_report(self, save_path: Optional[str] = None):\n","    \"\"\"\n","    Generate a comprehensive evaluation report combining all metrics.\n","\n","    Args:\n","        save_path: Optional path to save the report as HTML\n","\n","    Returns:\n","        Dictionary containing complete evaluation summary\n","    \"\"\"\n","    print(\"\\nüìã GENERATING COMPREHENSIVE EVALUATION REPORT\")\n","    print(\"=\" * 50)\n","\n","    report = {\n","        'metadata': {\n","            'evaluation_timestamp': datetime.now(),\n","            'total_tables': len(self.real_data),\n","            'total_relationships': len(self.metadata.to_dict().get('relationships', [])),\n","            'training_duration': self.generation_stats.get('training_duration', 'N/A'),\n","            'generation_duration': self.generation_stats.get('generation_duration', 'N/A')\n","        },\n","        'table_statistics': self.table_stats,\n","        'generation_statistics': self.generation_stats,\n","        'evaluation_scores': self.evaluation_scores,\n","        'diagnostic_results': getattr(self.diagnostic_report, 'get_results', lambda: {})(),\n","        'quality_results': getattr(self.quality_report, 'get_results', lambda: {})()\n","    }\n","\n","    # Display summary\n","    print(\"üìä COMPREHENSIVE EVALUATION SUMMARY:\")\n","    print(f\"   üìÖ Evaluation Date: {report['metadata']['evaluation_timestamp']}\")\n","    print(f\"   üìã Tables Processed: {report['metadata']['total_tables']}\")\n","    print(f\"   üîó Relationships: {report['metadata']['total_relationships']}\")\n","\n","    if 'training_duration' in self.generation_stats:\n","        print(f\"   ‚è±Ô∏è  Training Time: {self.generation_stats['training_duration']:.2f} seconds\")\n","    if 'generation_duration' in self.generation_stats:\n","        print(f\"   ‚ö° Generation Time: {self.generation_stats['generation_duration']:.2f} seconds\")\n","\n","    # Overall quality assessment\n","    diagnostic_scores = self.evaluation_scores.get('diagnostic', {})\n","    quality_scores = self.evaluation_scores.get('quality', {})\n","\n","    if diagnostic_scores or quality_scores:\n","        print(\"\\nüéØ KEY PERFORMANCE METRICS:\")\n","\n","        for metric, value in diagnostic_scores.items():\n","            if isinstance(value, (int, float)):\n","                print(f\"   üìä {metric}: {value:.3f}\")\n","\n","        for metric, value in quality_scores.items():\n","            if isinstance(value, (int, float)):\n","                print(f\"   üìà {metric}: {value:.3f}\")\n","\n","    # Save report if path provided\n","    if save_path:\n","        try:\n","            import json\n","            with open(save_path, 'w') as f:\n","                # Convert datetime objects to strings for JSON serialization\n","                json_report = report.copy()\n","                json_report['metadata']['evaluation_timestamp'] = str(json_report['metadata']['evaluation_timestamp'])\n","                if 'training_start' in json_report['generation_statistics']:\n","                    json_report['generation_statistics']['training_start'] = str(json_report['generation_statistics']['training_start'])\n","                if 'training_end' in json_report['generation_statistics']:\n","                    json_report['generation_statistics']['training_end'] = str(json_report['generation_statistics']['training_end'])\n","\n","                json.dump(json_report, f, indent=2, default=str)\n","            print(f\"üíæ Report saved to: {save_path}\")\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Warning: Could not save report to {save_path}: {e}\")\n","\n","    return report\n","\n","# Add methods to the class\n","RecursiveMultiTableSynthesizer.run_diagnostic_evaluation = run_diagnostic_evaluation\n","RecursiveMultiTableSynthesizer.run_quality_evaluation = run_quality_evaluation\n","RecursiveMultiTableSynthesizer.generate_evaluation_report = generate_evaluation_report\n","\n","print(\"‚úì Advanced evaluation methods added to class\")\n","print(\"‚úÖ RecursiveMultiTableSynthesizer class is now complete with all advanced features!\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1758511048209,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"nMJkK8LnNIxj","outputId":"a4190817-96cd-4b9b-87f2-81740eecbaa4"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Enterprise dataset creation function defined\n"]}],"source":["def create_enterprise_healthcare_data():\n","    \"\"\"\n","    Create a comprehensive enterprise dataset with 20 interconnected tables\n","    representing a healthcare-retail business with complex relationships.\n","\n","    Tables Created:\n","    1. companies - Parent organizations\n","    2. departments - Company departments\n","    3. locations - Physical locations\n","    4. employees - Staff members (with hierarchy)\n","    5. customers - Customer base\n","    6. products - Product catalog\n","    7. suppliers - Product suppliers\n","    8. categories - Product categories\n","    9. transactions - Sales transactions\n","    10. transaction_items - Individual items in transactions\n","    11. medical_records - Patient medical history\n","    12. medical_reports - Diagnostic reports\n","    13. prescriptions - Medical prescriptions\n","    14. appointments - Medical appointments\n","    15. insurance_policies - Insurance information\n","    16. claims - Insurance claims\n","    17. inventory - Product inventory\n","    18. reviews - Product/service reviews\n","    19. loyalty_programs - Customer loyalty\n","    20. audit_logs - System audit trail\n","    \"\"\"\n","    print(\"üèóÔ∏è  CREATING ENTERPRISE HEALTHCARE DATASET\")\n","    print(\"=\" * 50)\n","    print(\"Creating 20 interconnected tables with complex relationships...\")\n","\n","    # Set random seed for reproducibility\n","    np.random.seed(42)\n","    fake.seed_instance(42)\n","\n","    # 1. COMPANIES (Root table)\n","    print(\"1Ô∏è‚É£  Creating companies...\")\n","    companies = pd.DataFrame({\n","        'company_id': range(1, 6),  # 5 companies\n","        'company_name': [fake.company() for _ in range(5)],\n","        'company_type': np.random.choice(['Healthcare', 'Retail', 'Mixed'], 5),\n","        'founded_year': np.random.randint(1990, 2020, 5),\n","        'headquarters': [fake.city() for _ in range(5)],\n","        'annual_revenue': np.round(np.random.uniform(1000000, 100000000, 5), 2),\n","        'employee_count': np.random.randint(100, 5000, 5)\n","    })\n","\n","    # 2. DEPARTMENTS\n","    print(\"2Ô∏è‚É£  Creating departments...\")\n","    departments = pd.DataFrame({\n","        'dept_id': range(1, 26),  # 25 departments\n","        'company_id': np.random.choice(companies['company_id'], 25),\n","        'dept_name': np.random.choice([\n","            'Emergency', 'Cardiology', 'Oncology', 'Pediatrics', 'Surgery',\n","            'Pharmacy', 'Retail', 'Customer Service', 'IT', 'HR', 'Finance'\n","        ], 25),\n","        'budget': np.round(np.random.uniform(100000, 5000000, 25), 2),\n","        'manager_name': [fake.name() for _ in range(25)],\n","        'location_floor': np.random.randint(1, 10, 25)\n","    })\n","\n","    # 3. LOCATIONS\n","    print(\"3Ô∏è‚É£  Creating locations...\")\n","    locations = pd.DataFrame({\n","        'location_id': range(1, 16),  # 15 locations\n","        'company_id': np.random.choice(companies['company_id'], 15),\n","        'location_name': [fake.city() + ' Branch' for _ in range(15)],\n","        'address': [fake.address() for _ in range(15)],\n","        'city': [fake.city() for _ in range(15)],\n","        'state': [fake.state_abbr() for _ in range(15)],\n","        'zip_code': [fake.zipcode() for _ in range(15)],\n","        'phone': [fake.phone_number() for _ in range(15)],\n","        'facility_type': np.random.choice(['Hospital', 'Clinic', 'Retail Store', 'Warehouse'], 15),\n","        'square_feet': np.random.randint(1000, 50000, 15)\n","    })\n","\n","    # 4. EMPLOYEES (with self-referencing hierarchy)\n","    print(\"4Ô∏è‚É£  Creating employees with hierarchy...\")\n","    employees = pd.DataFrame({\n","        'employee_id': range(1, 201),  # 200 employees\n","        'dept_id': np.random.choice(departments['dept_id'], 200),\n","        'location_id': np.random.choice(locations['location_id'], 200),\n","        'first_name': [fake.first_name() for _ in range(200)],\n","        'last_name': [fake.last_name() for _ in range(200)],\n","        'email': [fake.email() for _ in range(200)],\n","        'phone': [fake.phone_number() for _ in range(200)],\n","        'hire_date': [fake.date_between(start_date='-5y', end_date='today') for _ in range(200)],\n","        'salary': np.round(np.random.uniform(35000, 120000, 200), 2),\n","        'position': np.random.choice([\n","            'Doctor', 'Nurse', 'Technician', 'Administrator', 'Pharmacist',\n","            'Sales Associate', 'Manager', 'Analyst', 'Specialist'\n","        ], 200),\n","        'employment_status': np.random.choice(['Full-time', 'Part-time', 'Contract'], 200, p=[0.7, 0.2, 0.1]),\n","        'reports_to': [None] * 150 + list(np.random.choice(range(1, 151), 50))  # Hierarchy\n","    })\n","\n","    # 5. CUSTOMERS\n","    print(\"5Ô∏è‚É£  Creating customers...\")\n","    customers = pd.DataFrame({\n","        'customer_id': range(1, 1001),  # 1000 customers\n","        'first_name': [fake.first_name() for _ in range(1000)],\n","        'last_name': [fake.last_name() for _ in range(1000)],\n","        'email': [fake.email() for _ in range(1000)],\n","        'phone': [fake.phone_number() for _ in range(1000)],\n","        'date_of_birth': [fake.date_of_birth(minimum_age=18, maximum_age=80) for _ in range(1000)],\n","        'gender': np.random.choice(['M', 'F', 'Other'], 1000, p=[0.45, 0.45, 0.1]),\n","        'address': [fake.address() for _ in range(1000)],\n","        'city': [fake.city() for _ in range(1000)],\n","        'state': [fake.state_abbr() for _ in range(1000)],\n","        'zip_code': [fake.zipcode() for _ in range(1000)],\n","        'registration_date': [fake.date_between(start_date='-3y', end_date='today') for _ in range(1000)],\n","        'customer_type': np.random.choice(['Individual', 'Business', 'Insurance'], 1000, p=[0.8, 0.15, 0.05])\n","    })\n","\n","    # 6. CATEGORIES\n","    print(\"6Ô∏è‚É£  Creating product categories...\")\n","    categories = pd.DataFrame({\n","        'category_id': range(1, 21),  # 20 categories\n","        'category_name': [\n","            'Prescription Drugs', 'Over-the-Counter', 'Medical Devices', 'First Aid',\n","            'Vitamins & Supplements', 'Personal Care', 'Baby Care', 'Beauty',\n","            'Health & Wellness', 'Mobility Aids', 'Dental Care', 'Vision Care',\n","            'Pain Relief', 'Allergy Relief', 'Diabetes Care', 'Heart Health',\n","            'Mental Health', 'Skin Care', 'Nutrition', 'Emergency Supplies'\n","        ],\n","        'parent_category_id': [None] * 10 + list(np.random.choice(range(1, 11), 10)),  # Hierarchy\n","        'description': [fake.text(max_nb_chars=200) for _ in range(20)],\n","        'is_prescription_required': np.random.choice([True, False], 20, p=[0.3, 0.7])\n","    })\n","\n","    # 7. PRODUCTS\n","    print(\"7Ô∏è‚É£  Creating products...\")\n","    products = pd.DataFrame({\n","        'product_id': range(1, 501),  # 500 products\n","        'category_id': np.random.choice(categories['category_id'], 500),\n","        'product_name': [fake.catch_phrase() + ' ' + fake.word() for _ in range(500)],\n","        'description': [fake.text(max_nb_chars=300) for _ in range(500)],\n","        'sku': [fake.bothify(text='???-###-???') for _ in range(500)],\n","        'price': np.round(np.random.uniform(5.99, 299.99, 500), 2),\n","        'cost': np.round(np.random.uniform(2.99, 150.00, 500), 2),\n","        'manufacturer': [fake.company() for _ in range(500)],\n","        'requires_prescription': np.random.choice([True, False], 500, p=[0.2, 0.8]),\n","        'dosage_form': np.random.choice([\n","            'Tablet', 'Capsule', 'Liquid', 'Cream', 'Injection', 'Device', 'Other'\n","        ], 500),\n","        'expiry_months': np.random.randint(6, 60, 500)\n","    })\n","\n","    # 8. SUPPLIERS\n","    print(\"8Ô∏è‚É£  Creating suppliers...\")\n","    suppliers = pd.DataFrame({\n","        'supplier_id': range(1, 51),  # 50 suppliers\n","        'supplier_name': [fake.company() for _ in range(50)],\n","        'contact_person': [fake.name() for _ in range(50)],\n","        'email': [fake.email() for _ in range(50)],\n","        'phone': [fake.phone_number() for _ in range(50)],\n","        'address': [fake.address() for _ in range(50)],\n","        'city': [fake.city() for _ in range(50)],\n","        'state': [fake.state_abbr() for _ in range(50)],\n","        'rating': np.round(np.random.uniform(3.0, 5.0, 50), 1),\n","        'established_year': np.random.randint(1980, 2020, 50),\n","        'specialty': np.random.choice([\n","            'Pharmaceuticals', 'Medical Devices', 'Personal Care', 'Vitamins'\n","        ], 50)\n","    })\n","\n","    # 9. TRANSACTIONS\n","    print(\"9Ô∏è‚É£  Creating transactions...\")\n","    transactions = pd.DataFrame({\n","        'transaction_id': range(1, 2001),  # 2000 transactions\n","        'customer_id': np.random.choice(customers['customer_id'], 2000),\n","        'employee_id': np.random.choice(employees['employee_id'], 2000),\n","        'location_id': np.random.choice(locations['location_id'], 2000),\n","        'transaction_date': [\n","            fake.date_time_between(start_date='-1y', end_date='now') for _ in range(2000)\n","        ],\n","        'transaction_type': np.random.choice(['Sale', 'Return', 'Exchange'], 2000, p=[0.85, 0.1, 0.05]),\n","        'payment_method': np.random.choice([\n","            'Credit Card', 'Debit Card', 'Cash', 'Insurance', 'HSA'\n","        ], 2000, p=[0.4, 0.25, 0.15, 0.15, 0.05]),\n","        'subtotal': np.round(np.random.uniform(10.00, 500.00, 2000), 2),\n","        'tax_amount': lambda x: np.round(x * 0.08, 2),  # Will be calculated\n","        'discount_amount': np.round(np.random.uniform(0, 50.00, 2000), 2),\n","        'total_amount': lambda x: x,  # Will be calculated\n","        'prescription_required': np.random.choice([True, False], 2000, p=[0.3, 0.7])\n","    })\n","    # Calculate derived fields\n","    transactions['tax_amount'] = np.round(transactions['subtotal'] * 0.08, 2)\n","    transactions['total_amount'] = np.round(\n","        transactions['subtotal'] + transactions['tax_amount'] - transactions['discount_amount'], 2\n","    )\n","\n","    # 10. TRANSACTION_ITEMS\n","    print(\"üîü Creating transaction items...\")\n","    transaction_items = pd.DataFrame({\n","        'item_id': range(1, 5001),  # 5000 items\n","        'transaction_id': np.random.choice(transactions['transaction_id'], 5000),\n","        'product_id': np.random.choice(products['product_id'], 5000),\n","        'quantity': np.random.randint(1, 5, 5000),\n","        'unit_price': np.round(np.random.uniform(5.99, 299.99, 5000), 2),\n","        'discount_percent': np.round(np.random.uniform(0, 20, 5000), 1),\n","        'line_total': lambda x: x  # Will be calculated\n","    })\n","    # Calculate line totals\n","    transaction_items['line_total'] = np.round(\n","        transaction_items['quantity'] * transaction_items['unit_price'] *\n","        (1 - transaction_items['discount_percent'] / 100), 2\n","    )\n","\n","    # 11. MEDICAL_RECORDS\n","    print(\"1Ô∏è‚É£1Ô∏è‚É£ Creating medical records...\")\n","    medical_records = pd.DataFrame({\n","        'record_id': range(1, 801),  # 800 records\n","        'customer_id': np.random.choice(customers['customer_id'], 800),\n","        'employee_id': np.random.choice(employees['employee_id'], 800),  # Doctor/Nurse\n","        'location_id': np.random.choice(locations['location_id'], 800),\n","        'record_date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(800)],\n","        'diagnosis': [fake.catch_phrase() for _ in range(800)],\n","        'symptoms': [fake.text(max_nb_chars=200) for _ in range(800)],\n","        'treatment': [fake.text(max_nb_chars=200) for _ in range(800)],\n","        'allergies': [fake.word() if np.random.random() < 0.3 else None for _ in range(800)],\n","        'blood_pressure': [f\"{np.random.randint(90, 180)}/{np.random.randint(60, 120)}\" for _ in range(800)],\n","        'heart_rate': np.random.randint(60, 100, 800),\n","        'weight_kg': np.round(np.random.uniform(40, 120, 800), 1),\n","        'height_cm': np.random.randint(140, 200, 800)\n","    })\n","\n","    # 12. MEDICAL_REPORTS\n","    print(\"1Ô∏è‚É£2Ô∏è‚É£ Creating medical reports...\")\n","    medical_reports = pd.DataFrame({\n","        'report_id': range(1, 401),  # 400 reports\n","        'record_id': np.random.choice(medical_records['record_id'], 400),\n","        'employee_id': np.random.choice(employees['employee_id'], 400),  # Technician/Doctor\n","        'report_type': np.random.choice([\n","            'Blood Test', 'X-Ray', 'MRI', 'CT Scan', 'Ultrasound', 'EKG', 'Biopsy'\n","        ], 400),\n","        'report_date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(400)],\n","        'findings': [fake.text(max_nb_chars=400) for _ in range(400)],\n","        'recommendations': [fake.text(max_nb_chars=200) for _ in range(400)],\n","        'urgency_level': np.random.choice(['Low', 'Medium', 'High', 'Critical'], 400, p=[0.4, 0.35, 0.2, 0.05]),\n","        'is_abnormal': np.random.choice([True, False], 400, p=[0.3, 0.7]),\n","        'cost': np.round(np.random.uniform(50.00, 2000.00, 400), 2)\n","    })\n","\n","    # 13. PRESCRIPTIONS\n","    print(\"1Ô∏è‚É£3Ô∏è‚É£ Creating prescriptions...\")\n","    prescriptions = pd.DataFrame({\n","        'prescription_id': range(1, 601),  # 600 prescriptions\n","        'record_id': np.random.choice(medical_records['record_id'], 600),\n","        'product_id': np.random.choice(\n","            products[products['requires_prescription'] == True]['product_id'], 600\n","        ),\n","        'prescribing_doctor': np.random.choice(employees['employee_id'], 600),\n","        'prescription_date': [fake.date_between(start_date='-1y', end_date='today') for _ in range(600)],\n","        'dosage': [f\"{np.random.randint(1, 4)} times daily\" for _ in range(600)],\n","        'quantity_prescribed': np.random.randint(30, 90, 600),\n","        'refills_remaining': np.random.randint(0, 5, 600),\n","        'expiry_date': [fake.date_between(start_date='today', end_date='+1y') for _ in range(600)],\n","        'is_filled': np.random.choice([True, False], 600, p=[0.8, 0.2]),\n","        'pharmacy_notes': [fake.text(max_nb_chars=100) if np.random.random() < 0.3 else None for _ in range(600)]\n","    })\n","\n","    # 14. APPOINTMENTS\n","    print(\"1Ô∏è‚É£4Ô∏è‚É£ Creating appointments...\")\n","    appointments = pd.DataFrame({\n","        'appointment_id': range(1, 1201),  # 1200 appointments\n","        'customer_id': np.random.choice(customers['customer_id'], 1200),\n","        'employee_id': np.random.choice(employees['employee_id'], 1200),  # Doctor/Specialist\n","        'location_id': np.random.choice(locations['location_id'], 1200),\n","        'appointment_date': [\n","            fake.date_time_between(start_date='-30d', end_date='+30d') for _ in range(1200)\n","        ],\n","        'appointment_type': np.random.choice([\n","            'Consultation', 'Follow-up', 'Emergency', 'Routine Check', 'Specialist Visit'\n","        ], 1200),\n","        'status': np.random.choice([\n","            'Scheduled', 'Completed', 'Cancelled', 'No-Show', 'Rescheduled'\n","        ], 1200, p=[0.3, 0.5, 0.1, 0.05, 0.05]),\n","        'duration_minutes': np.random.choice([15, 30, 45, 60, 90], 1200, p=[0.1, 0.4, 0.3, 0.15, 0.05]),\n","        'reason': [fake.text(max_nb_chars=100) for _ in range(1200)],\n","        'notes': [fake.text(max_nb_chars=200) if np.random.random() < 0.4 else None for _ in range(1200)]\n","    })\n","\n","    # 15. INSURANCE_POLICIES\n","    print(\"1Ô∏è‚É£5Ô∏è‚É£ Creating insurance policies...\")\n","    insurance_policies = pd.DataFrame({\n","        'policy_id': range(1, 701),  # 700 policies\n","        'customer_id': np.random.choice(customers['customer_id'], 700),\n","        'policy_number': [fake.bothify(text='POL-####-????') for _ in range(700)],\n","        'insurance_company': [fake.company() + ' Insurance' for _ in range(700)],\n","        'policy_type': np.random.choice(['Health', 'Dental', 'Vision', 'Prescription'], 700),\n","        'start_date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(700)],\n","        'end_date': [fake.date_between(start_date='today', end_date='+1y') for _ in range(700)],\n","        'premium_amount': np.round(np.random.uniform(100.00, 800.00, 700), 2),\n","        'deductible': np.round(np.random.uniform(500.00, 5000.00, 700), 2),\n","        'copay': np.round(np.random.uniform(10.00, 50.00, 700), 2),\n","        'coverage_percent': np.random.choice([70, 80, 85, 90, 100], 700),\n","        'is_active': np.random.choice([True, False], 700, p=[0.9, 0.1])\n","    })\n","\n","    # 16. CLAIMS\n","    print(\"1Ô∏è‚É£6Ô∏è‚É£ Creating insurance claims...\")\n","    claims = pd.DataFrame({\n","        'claim_id': range(1, 301),  # 300 claims\n","        'policy_id': np.random.choice(insurance_policies['policy_id'], 300),\n","        'transaction_id': np.random.choice(transactions['transaction_id'], 300),\n","        'claim_number': [fake.bothify(text='CLM-######') for _ in range(300)],\n","        'claim_date': [fake.date_between(start_date='-1y', end_date='today') for _ in range(300)],\n","        'claim_amount': np.round(np.random.uniform(50.00, 5000.00, 300), 2),\n","        'approved_amount': lambda x: x,  # Will be calculated\n","        'status': np.random.choice([\n","            'Submitted', 'Under Review', 'Approved', 'Denied', 'Paid'\n","        ], 300, p=[0.1, 0.2, 0.4, 0.1, 0.2]),\n","        'denial_reason': [\n","            fake.text(max_nb_chars=100) if np.random.random() < 0.1 else None for _ in range(300)\n","        ],\n","        'processing_date': [\n","            fake.date_between(start_date='-1y', end_date='today') for _ in range(300)\n","        ]\n","    })\n","    # Calculate approved amounts\n","    claims['approved_amount'] = np.where(\n","        claims['status'] == 'Denied', 0,\n","        np.round(claims['claim_amount'] * np.random.uniform(0.5, 1.0, 300), 2)\n","    )\n","\n","    # 17. INVENTORY\n","    print(\"1Ô∏è‚É£7Ô∏è‚É£ Creating inventory...\")\n","    inventory = pd.DataFrame({\n","        'inventory_id': range(1, 1001),  # 1000 inventory records\n","        'product_id': np.random.choice(products['product_id'], 1000),\n","        'location_id': np.random.choice(locations['location_id'], 1000),\n","        'supplier_id': np.random.choice(suppliers['supplier_id'], 1000),\n","        'quantity_on_hand': np.random.randint(0, 500, 1000),\n","        'reorder_level': np.random.randint(10, 100, 1000),\n","        'max_stock_level': np.random.randint(200, 1000, 1000),\n","        'last_restock_date': [fake.date_between(start_date='-6m', end_date='today') for _ in range(1000)],\n","        'expiry_date': [fake.date_between(start_date='today', end_date='+2y') for _ in range(1000)],\n","        'lot_number': [fake.bothify(text='LOT-####-??') for _ in range(1000)],\n","        'unit_cost': np.round(np.random.uniform(1.00, 100.00, 1000), 2),\n","        'storage_location': [fake.bothify(text='?##-??##') for _ in range(1000)]\n","    })\n","\n","    # 18. REVIEWS\n","    print(\"1Ô∏è‚É£8Ô∏è‚É£ Creating reviews...\")\n","    reviews = pd.DataFrame({\n","        'review_id': range(1, 1501),  # 1500 reviews\n","        'customer_id': np.random.choice(customers['customer_id'], 1500),\n","        'product_id': np.random.choice(products['product_id'], 1500),\n","        'transaction_id': np.random.choice(transactions['transaction_id'], 1500),\n","        'rating': np.random.choice([1, 2, 3, 4, 5], 1500, p=[0.05, 0.1, 0.15, 0.35, 0.35]),\n","        'review_text': [fake.text(max_nb_chars=300) for _ in range(1500)],\n","        'review_date': [fake.date_between(start_date='-1y', end_date='today') for _ in range(1500)],\n","        'verified_purchase': np.random.choice([True, False], 1500, p=[0.8, 0.2]),\n","        'helpful_votes': np.random.randint(0, 50, 1500),\n","        'response_from_business': [\n","            fake.text(max_nb_chars=150) if np.random.random() < 0.2 else None for _ in range(1500)\n","        ]\n","    })\n","\n","    # 19. LOYALTY_PROGRAMS\n","    print(\"1Ô∏è‚É£9Ô∏è‚É£ Creating loyalty programs...\")\n","    loyalty_programs = pd.DataFrame({\n","        'loyalty_id': range(1, 801),  # 800 loyalty memberships\n","        'customer_id': np.random.choice(customers['customer_id'], 800),\n","        'program_name': np.random.choice([\n","            'HealthPlus Rewards', 'Wellness Circle', 'Premium Care', 'Family Benefits'\n","        ], 800),\n","        'membership_level': np.random.choice(['Bronze', 'Silver', 'Gold', 'Platinum'], 800),\n","        'join_date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(800)],\n","        'points_balance': np.random.randint(0, 5000, 800),\n","        'points_earned_total': np.random.randint(100, 10000, 800),\n","        'points_redeemed_total': np.random.randint(0, 8000, 800),\n","        'last_activity_date': [fake.date_between(start_date='-3m', end_date='today') for _ in range(800)],\n","        'is_active': np.random.choice([True, False], 800, p=[0.85, 0.15]),\n","        'annual_spending': np.round(np.random.uniform(200.00, 5000.00, 800), 2)\n","    })\n","\n","    # 20. AUDIT_LOGS\n","    print(\"2Ô∏è‚É£0Ô∏è‚É£ Creating audit logs...\")\n","    audit_logs = pd.DataFrame({\n","        'log_id': range(1, 3001),  # 3000 audit entries\n","        'user_id': np.random.choice(employees['employee_id'], 3000),\n","        'action': np.random.choice([\n","            'CREATE', 'UPDATE', 'DELETE', 'LOGIN', 'LOGOUT', 'VIEW', 'EXPORT'\n","        ], 3000, p=[0.2, 0.3, 0.05, 0.15, 0.15, 0.1, 0.05]),\n","        'table_name': np.random.choice([\n","            'customers', 'transactions', 'medical_records', 'prescriptions',\n","            'appointments', 'inventory', 'products'\n","        ], 3000),\n","        'record_id': np.random.randint(1, 1000, 3000),\n","        'timestamp': [\n","            fake.date_time_between(start_date='-6m', end_date='now') for _ in range(3000)\n","        ],\n","        'ip_address': [fake.ipv4() for _ in range(3000)],\n","        'user_agent': [fake.user_agent() for _ in range(3000)],\n","        'session_id': [fake.bothify(text='SES-########-????') for _ in range(3000)],\n","        'details': [fake.text(max_nb_chars=200) if np.random.random() < 0.3 else None for _ in range(3000)]\n","    })\n","\n","    # Compile all tables\n","    enterprise_data = {\n","        'companies': companies,\n","        'departments': departments,\n","        'locations': locations,\n","        'employees': employees,\n","        'customers': customers,\n","        'categories': categories,\n","        'products': products,\n","        'suppliers': suppliers,\n","        'transactions': transactions,\n","        'transaction_items': transaction_items,\n","        'medical_records': medical_records,\n","        'medical_reports': medical_reports,\n","        'prescriptions': prescriptions,\n","        'appointments': appointments,\n","        'insurance_policies': insurance_policies,\n","        'claims': claims,\n","        'inventory': inventory,\n","        'reviews': reviews,\n","        'loyalty_programs': loyalty_programs,\n","        'audit_logs': audit_logs\n","    }\n","\n","    print(\"\\n‚úÖ ENTERPRISE DATASET CREATION COMPLETE!\")\n","    print(f\"üìä Created {len(enterprise_data)} interconnected tables\")\n","\n","    total_records = sum(len(df) for df in enterprise_data.values())\n","    print(f\"üìà Total records across all tables: {total_records:,}\")\n","\n","    # Display table summary\n","    print(\"\\nüìã TABLE SUMMARY:\")\n","    for table_name, df in enterprise_data.items():\n","        print(f\"   {table_name:20} | {len(df):6,} rows | {len(df.columns):2} columns\")\n","\n","    return enterprise_data\n","\n","print(\"‚úì Enterprise dataset creation function defined\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2956,"status":"ok","timestamp":1758511061781,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"ibNDW0H7S2D2","outputId":"92a98c44-8200-45e5-e8cc-225083f5d757"},"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ INITIALIZING COMPREHENSIVE ENTERPRISE DATASET\n","============================================================\n","üèóÔ∏è  CREATING ENTERPRISE HEALTHCARE DATASET\n","==================================================\n","Creating 20 interconnected tables with complex relationships...\n","1Ô∏è‚É£  Creating companies...\n","2Ô∏è‚É£  Creating departments...\n","3Ô∏è‚É£  Creating locations...\n","4Ô∏è‚É£  Creating employees with hierarchy...\n","5Ô∏è‚É£  Creating customers...\n","6Ô∏è‚É£  Creating product categories...\n","7Ô∏è‚É£  Creating products...\n","8Ô∏è‚É£  Creating suppliers...\n","9Ô∏è‚É£  Creating transactions...\n","üîü Creating transaction items...\n","1Ô∏è‚É£1Ô∏è‚É£ Creating medical records...\n","1Ô∏è‚É£2Ô∏è‚É£ Creating medical reports...\n","1Ô∏è‚É£3Ô∏è‚É£ Creating prescriptions...\n","1Ô∏è‚É£4Ô∏è‚É£ Creating appointments...\n","1Ô∏è‚É£5Ô∏è‚É£ Creating insurance policies...\n","1Ô∏è‚É£6Ô∏è‚É£ Creating insurance claims...\n","1Ô∏è‚É£7Ô∏è‚É£ Creating inventory...\n","1Ô∏è‚É£8Ô∏è‚É£ Creating reviews...\n","1Ô∏è‚É£9Ô∏è‚É£ Creating loyalty programs...\n","2Ô∏è‚É£0Ô∏è‚É£ Creating audit logs...\n","\n","‚úÖ ENTERPRISE DATASET CREATION COMPLETE!\n","üìä Created 20 interconnected tables\n","üìà Total records across all tables: 19,115\n","\n","üìã TABLE SUMMARY:\n","   companies            |      5 rows |  7 columns\n","   departments          |     25 rows |  6 columns\n","   locations            |     15 rows | 10 columns\n","   employees            |    200 rows | 12 columns\n","   customers            |  1,000 rows | 13 columns\n","   categories           |     20 rows |  5 columns\n","   products             |    500 rows | 11 columns\n","   suppliers            |     50 rows | 11 columns\n","   transactions         |  2,000 rows | 12 columns\n","   transaction_items    |  5,000 rows |  7 columns\n","   medical_records      |    800 rows | 13 columns\n","   medical_reports      |    400 rows | 10 columns\n","   prescriptions        |    600 rows | 11 columns\n","   appointments         |  1,200 rows | 10 columns\n","   insurance_policies   |    700 rows | 12 columns\n","   claims               |    300 rows | 10 columns\n","   inventory            |  1,000 rows | 12 columns\n","   reviews              |  1,500 rows | 10 columns\n","   loyalty_programs     |    800 rows | 11 columns\n","   audit_logs           |  3,000 rows | 10 columns\n","\n","üîç DETAILED DATASET ANALYSIS\n","============================================================\n","üìä OVERALL STATISTICS:\n","   üìã Total Tables: 20\n","   üìà Total Records: 19,115\n","   üìù Total Columns: 203\n","   üíæ Total Memory: 5.89 MB\n","\n","üîç DATA TYPE ANALYSIS:\n","   üî¢ Numeric Columns: 98\n","   üìù Categorical Columns: 94\n","   üìÖ DateTime Columns: 3\n","\n","üëÄ SAMPLE DATA FROM KEY TABLES:\n","\n","üìã COMPANIES (Sample - showing first 3 rows):\n","   Shape: (5, 7)\n"," company_id                    company_name company_type  founded_year   headquarters  annual_revenue  employee_count\n","          1 Rodriguez, Figueroa and Sanchez        Mixed          2010    New Maryton      6750277.60             869\n","          2                       Doyle Ltd   Healthcare          1996 New Roberttown     86751438.43            2491\n","          3      Banca Privada OLMJ S.L.N.E        Mixed          2015 East Jessetown     60510386.16            2533\n","\n","üìã CUSTOMERS (Sample - showing first 3 rows):\n","   Shape: (1000, 13)\n"," customer_id first_name last_name                     email  ... state zip_code registration_date customer_type\n","           1       Cloe    Pascal  bryanparsons@example.com  ...    HI    03678        2024-01-30      Business\n","           2    Corinne  Madrigal carterbradley@example.org  ...    AS    82960        2023-09-27    Individual\n","           3      David    Miller  martycamille@example.net  ...    MD    88143        2023-12-23    Individual\n","\n","üìã TRANSACTIONS (Sample - showing first 3 rows):\n","   Shape: (2000, 12)\n"," transaction_id  customer_id  employee_id  location_id  ... tax_amount discount_amount total_amount  prescription_required\n","              1          505          148            7  ...      22.97            3.38       306.70                  False\n","              2           73           82           10  ...      25.78            8.57       339.49                  False\n","              3          249          129            6  ...      29.78           49.22       352.87                  False\n","\n","üìã MEDICAL_RECORDS (Sample - showing first 3 rows):\n","   Shape: (800, 13)\n"," record_id  customer_id  employee_id  location_id  ... blood_pressure heart_rate weight_kg height_cm\n","         1          445          182           14  ...         104/76         61     101.7       175\n","         2          962           78            5  ...          95/64         87      70.3       196\n","         3          479           41            3  ...        122/113         82      96.7       157\n","\n","üìã PRODUCTS (Sample - showing first 3 rows):\n","   Shape: (500, 11)\n"," product_id  category_id                                     product_name                                                                                                                                                                                                                                                                                              description  ...        manufacturer  requires_prescription  dosage_form expiry_months\n","          1           16              L'art de louer sans soucis hospital                                                                                     Prix piti√© un plan pierre. Parti large retenir escalier de muet tombe.\\nFermer principe qualit√© figure passion mode. Rire davantage campagne battre beau quatre.\\nMot centre enfant fid√®le. Endormir nombre content.  ...          Benson LLC                  False        Other            44\n","          2            9         Inverse contextually-based algorithm quo Del √∫ltimos voy otras mediante blanco.\\nHicieron dentro derecho. Considera escuela buena palabra cual. Tienen informaci√≥n a√±o.\\nBastante considera espa√±ol fuera existe √∫nico. Sur pacientes perdido somos razones sectores.\\nNuevo llama produce sistema. Acciones alg√∫n estudio ayuda distintas ser√°n.  ... Familia Rom√°n S.C.P                  False       Liquid            31\n","          3           19 Configurable client-driven system engine r√©gimen                             According throw meeting many condition set pull. Understand kitchen point Mrs.\\nSingle several degree maybe floor. Line range until decision public food court.\\nSystem particular church what. President small sister especially usually line task. He fill risk stop firm.  ...           Green LLC                  False       Liquid            54\n","\n","‚úÖ Dataset initialization complete and ready for synthesis!\n","üîë Primary keys defined for all 20 tables\n"]}],"source":["print(\"üöÄ INITIALIZING COMPREHENSIVE ENTERPRISE DATASET\")\n","print(\"=\" * 60)\n","\n","# Create the enterprise dataset\n","enterprise_data = create_enterprise_healthcare_data()\n","\n","# Display comprehensive dataset overview\n","print(\"\\nüîç DETAILED DATASET ANALYSIS\")\n","print(\"=\" * 60)\n","\n","# Calculate comprehensive statistics\n","total_records = sum(len(df) for df in enterprise_data.values())\n","total_columns = sum(len(df.columns) for df in enterprise_data.values())\n","total_memory = sum(df.memory_usage(deep=True).sum() for df in enterprise_data.values()) / 1024 / 1024\n","\n","print(f\"üìä OVERALL STATISTICS:\")\n","print(f\"   üìã Total Tables: {len(enterprise_data)}\")\n","print(f\"   üìà Total Records: {total_records:,}\")\n","print(f\"   üìù Total Columns: {total_columns}\")\n","print(f\"   üíæ Total Memory: {total_memory:.2f} MB\")\n","\n","# Analyze data types across all tables\n","print(f\"\\nüîç DATA TYPE ANALYSIS:\")\n","numeric_cols = sum(len(df.select_dtypes(include=[np.number]).columns) for df in enterprise_data.values())\n","categorical_cols = sum(len(df.select_dtypes(include=['object', 'category']).columns) for df in enterprise_data.values())\n","datetime_cols = sum(len(df.select_dtypes(include=['datetime64']).columns) for df in enterprise_data.values())\n","\n","print(f\"   üî¢ Numeric Columns: {numeric_cols}\")\n","print(f\"   üìù Categorical Columns: {categorical_cols}\")\n","print(f\"   üìÖ DateTime Columns: {datetime_cols}\")\n","\n","# Show sample data from key tables\n","print(f\"\\nüëÄ SAMPLE DATA FROM KEY TABLES:\")\n","key_tables = ['companies', 'customers', 'transactions', 'medical_records', 'products']\n","\n","for table_name in key_tables:\n","    if table_name in enterprise_data:\n","        df = enterprise_data[table_name]\n","        print(f\"\\nüìã {table_name.upper()} (Sample - showing first 3 rows):\")\n","        print(f\"   Shape: {df.shape}\")\n","        print(df.head(3).to_string(index=False, max_cols=8))\n","\n","print(\"\\n‚úÖ Dataset initialization complete and ready for synthesis!\")\n","\n","# Define primary keys for all tables\n","primary_keys = {\n","    'companies': 'company_id',\n","    'departments': 'dept_id',\n","    'locations': 'location_id',\n","    'employees': 'employee_id',\n","    'customers': 'customer_id',\n","    'categories': 'category_id',\n","    'products': 'product_id',\n","    'suppliers': 'supplier_id',\n","    'transactions': 'transaction_id',\n","    'transaction_items': 'item_id',\n","    'medical_records': 'record_id',\n","    'medical_reports': 'report_id',\n","    'prescriptions': 'prescription_id',\n","    'appointments': 'appointment_id',\n","    'insurance_policies': 'policy_id',\n","    'claims': 'claim_id',\n","    'inventory': 'inventory_id',\n","    'reviews': 'review_id',\n","    'loyalty_programs': 'loyalty_id',\n","    'audit_logs': 'log_id'\n","}\n","\n","print(f\"üîë Primary keys defined for all {len(primary_keys)} tables\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1758511074051,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"PgDIGyBbNI0D","outputId":"3baa157d-e98c-4f45-b497-c8a4a0fd5c63"},"outputs":[{"output_type":"stream","name":"stdout","text":["ü§ñ INITIALIZING ENHANCED MULTI-TABLE SYNTHESIZER\n","============================================================\n","Enhanced RecursiveMultiTableSynthesizer initialized with gaussian_copula\n","Ready for automatic relationship detection and quality evaluation\n","\n","üîç Adding tables with automatic relationship detection...\n","\n","=== ADDING 20 TABLES WITH METADATA DETECTION ===\n","Adding tables with individual metadata detection...\n","Added table 'companies' with primary key 'company_id'\n","Added table 'departments' with primary key 'dept_id'\n","Added table 'locations' with primary key 'location_id'\n","Added table 'employees' with primary key 'employee_id'\n","Added table 'customers' with primary key 'customer_id'\n","Added table 'categories' with primary key 'category_id'\n","Added table 'products' with primary key 'product_id'\n","Added table 'suppliers' with primary key 'supplier_id'\n","Added table 'transactions' with primary key 'transaction_id'\n","Added table 'transaction_items' with primary key 'item_id'\n","Added table 'medical_records' with primary key 'record_id'\n","Added table 'medical_reports' with primary key 'report_id'\n","Added table 'prescriptions' with primary key 'prescription_id'\n","Added table 'appointments' with primary key 'appointment_id'\n","Added table 'insurance_policies' with primary key 'policy_id'\n","Added table 'claims' with primary key 'claim_id'\n","Added table 'inventory' with primary key 'inventory_id'\n","Added table 'reviews' with primary key 'review_id'\n","Added table 'loyalty_programs' with primary key 'loyalty_id'\n","Added table 'audit_logs' with primary key 'log_id'\n","\n","Generating comprehensive table statistics...\n","   Total rows across all tables: 19,115\n","   Total memory usage: 6.40 MB\n","Table statistics generated successfully\n","Successfully added 20 tables with metadata\n","\n","üìä ANALYZING AUTO-DETECTED RELATIONSHIPS...\n","\n","üîç ANALYZING RELATIONSHIP STRUCTURE\n","==================================================\n","üìä Total relationships detected: 0\n","üîÑ Self-referencing relationships: 0\n","üå≥ Hierarchical relationships: 0\n","\n","üìã METADATA DETECTION SUMMARY:\n","   üìã Tables processed: 20\n","   üîó Relationships detected: 0\n","   üå≥ Hierarchical relationships: 0\n","   üîÑ Self-referencing relationships: 0\n"]}],"source":["print(\"ü§ñ INITIALIZING ENHANCED MULTI-TABLE SYNTHESIZER\")\n","print(\"=\" * 60)\n","\n","# Initialize the enhanced synthesizer with Gaussian Copula\n","synthesizer = RecursiveMultiTableSynthesizer(synthesizer_type='gaussian_copula')\n","\n","# Add all tables with automatic metadata detection\n","print(\"\\nüîç Adding tables with automatic relationship detection...\")\n","synthesizer.add_tables_from_dict(enterprise_data, primary_keys=primary_keys)\n","\n","# Analyze automatically detected relationships\n","print(\"\\nüìä ANALYZING AUTO-DETECTED RELATIONSHIPS...\")\n","relationship_analysis = synthesizer.analyze_relationships()\n","\n","# Display metadata summary\n","print(f\"\\nüìã METADATA DETECTION SUMMARY:\")\n","metadata_dict = synthesizer.metadata.to_dict()\n","print(f\"   üìã Tables processed: {len(metadata_dict.get('tables', {}))}\")\n","print(f\"   üîó Relationships detected: {relationship_analysis.get('total_relationships', 0)}\")\n","print(f\"   üå≥ Hierarchical relationships: {relationship_analysis.get('hierarchical', 0)}\")\n","print(f\"   üîÑ Self-referencing relationships: {relationship_analysis.get('self_referencing', 0)}\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1758511085952,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"JlCwNIlTPmvY","outputId":"3b083bdb-e338-4215-bedd-08b65b28b596"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'tables': {'companies': {'primary_key': 'company_id',\n","   'columns': {'company_id': {'sdtype': 'id'},\n","    'company_name': {'sdtype': 'categorical'},\n","    'company_type': {'sdtype': 'categorical'},\n","    'founded_year': {'sdtype': 'numerical'},\n","    'headquarters': {'sdtype': 'categorical'},\n","    'annual_revenue': {'sdtype': 'numerical'},\n","    'employee_count': {'sdtype': 'numerical'}}},\n","  'departments': {'primary_key': 'dept_id',\n","   'columns': {'dept_id': {'sdtype': 'id'},\n","    'company_id': {'sdtype': 'id'},\n","    'dept_name': {'sdtype': 'categorical'},\n","    'budget': {'sdtype': 'numerical'},\n","    'manager_name': {'sdtype': 'categorical'},\n","    'location_floor': {'sdtype': 'numerical'}}},\n","  'locations': {'primary_key': 'location_id',\n","   'columns': {'location_id': {'sdtype': 'id'},\n","    'company_id': {'sdtype': 'id'},\n","    'location_name': {'sdtype': 'categorical'},\n","    'address': {'sdtype': 'categorical'},\n","    'city': {'pii': True, 'sdtype': 'city'},\n","    'state': {'pii': True, 'sdtype': 'administrative_unit'},\n","    'zip_code': {'pii': True, 'sdtype': 'postcode'},\n","    'phone': {'sdtype': 'categorical'},\n","    'facility_type': {'sdtype': 'categorical'},\n","    'square_feet': {'sdtype': 'numerical'}}},\n","  'employees': {'primary_key': 'employee_id',\n","   'columns': {'employee_id': {'sdtype': 'id'},\n","    'dept_id': {'sdtype': 'id'},\n","    'location_id': {'sdtype': 'id'},\n","    'first_name': {'pii': True, 'sdtype': 'first_name'},\n","    'last_name': {'pii': True, 'sdtype': 'last_name'},\n","    'email': {'pii': True, 'sdtype': 'email'},\n","    'phone': {'sdtype': 'categorical'},\n","    'hire_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'salary': {'sdtype': 'numerical'},\n","    'position': {'sdtype': 'categorical'},\n","    'employment_status': {'sdtype': 'categorical'},\n","    'reports_to': {'sdtype': 'numerical'}}},\n","  'customers': {'primary_key': 'customer_id',\n","   'columns': {'customer_id': {'sdtype': 'id'},\n","    'first_name': {'pii': True, 'sdtype': 'first_name'},\n","    'last_name': {'pii': True, 'sdtype': 'last_name'},\n","    'email': {'pii': True, 'sdtype': 'email'},\n","    'phone': {'sdtype': 'categorical'},\n","    'date_of_birth': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'gender': {'sdtype': 'categorical'},\n","    'address': {'sdtype': 'categorical'},\n","    'city': {'pii': True, 'sdtype': 'city'},\n","    'state': {'pii': True, 'sdtype': 'administrative_unit'},\n","    'zip_code': {'pii': True, 'sdtype': 'postcode'},\n","    'registration_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'customer_type': {'sdtype': 'categorical'}}},\n","  'categories': {'primary_key': 'category_id',\n","   'columns': {'category_id': {'sdtype': 'id'},\n","    'category_name': {'sdtype': 'categorical'},\n","    'parent_category_id': {'sdtype': 'id'},\n","    'description': {'sdtype': 'categorical'},\n","    'is_prescription_required': {'sdtype': 'categorical'}}},\n","  'products': {'primary_key': 'product_id',\n","   'columns': {'product_id': {'sdtype': 'id'},\n","    'category_id': {'sdtype': 'id'},\n","    'product_name': {'sdtype': 'categorical'},\n","    'description': {'sdtype': 'categorical'},\n","    'sku': {'sdtype': 'categorical'},\n","    'price': {'sdtype': 'numerical'},\n","    'cost': {'sdtype': 'numerical'},\n","    'manufacturer': {'sdtype': 'categorical'},\n","    'requires_prescription': {'sdtype': 'categorical'},\n","    'dosage_form': {'sdtype': 'categorical'},\n","    'expiry_months': {'sdtype': 'numerical'}}},\n","  'suppliers': {'primary_key': 'supplier_id',\n","   'columns': {'supplier_id': {'sdtype': 'id'},\n","    'supplier_name': {'sdtype': 'categorical'},\n","    'contact_person': {'sdtype': 'categorical'},\n","    'email': {'pii': True, 'sdtype': 'email'},\n","    'phone': {'sdtype': 'categorical'},\n","    'address': {'sdtype': 'categorical'},\n","    'city': {'pii': True, 'sdtype': 'city'},\n","    'state': {'pii': True, 'sdtype': 'administrative_unit'},\n","    'rating': {'sdtype': 'numerical'},\n","    'established_year': {'sdtype': 'numerical'},\n","    'specialty': {'sdtype': 'categorical'}}},\n","  'transactions': {'primary_key': 'transaction_id',\n","   'columns': {'transaction_id': {'sdtype': 'id'},\n","    'customer_id': {'sdtype': 'id'},\n","    'employee_id': {'sdtype': 'id'},\n","    'location_id': {'sdtype': 'id'},\n","    'transaction_date': {'sdtype': 'datetime'},\n","    'transaction_type': {'sdtype': 'categorical'},\n","    'payment_method': {'sdtype': 'categorical'},\n","    'subtotal': {'sdtype': 'numerical'},\n","    'tax_amount': {'sdtype': 'numerical'},\n","    'discount_amount': {'sdtype': 'numerical'},\n","    'total_amount': {'sdtype': 'numerical'},\n","    'prescription_required': {'sdtype': 'categorical'}}},\n","  'transaction_items': {'primary_key': 'item_id',\n","   'columns': {'item_id': {'sdtype': 'id'},\n","    'transaction_id': {'sdtype': 'id'},\n","    'product_id': {'sdtype': 'id'},\n","    'quantity': {'sdtype': 'categorical'},\n","    'unit_price': {'sdtype': 'numerical'},\n","    'discount_percent': {'sdtype': 'numerical'},\n","    'line_total': {'sdtype': 'numerical'}}},\n","  'medical_records': {'primary_key': 'record_id',\n","   'columns': {'record_id': {'sdtype': 'id'},\n","    'customer_id': {'sdtype': 'id'},\n","    'employee_id': {'sdtype': 'id'},\n","    'location_id': {'sdtype': 'id'},\n","    'record_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'diagnosis': {'sdtype': 'categorical'},\n","    'symptoms': {'sdtype': 'categorical'},\n","    'treatment': {'sdtype': 'categorical'},\n","    'allergies': {'sdtype': 'categorical'},\n","    'blood_pressure': {'sdtype': 'categorical'},\n","    'heart_rate': {'sdtype': 'numerical'},\n","    'weight_kg': {'sdtype': 'numerical'},\n","    'height_cm': {'sdtype': 'numerical'}}},\n","  'medical_reports': {'primary_key': 'report_id',\n","   'columns': {'report_id': {'sdtype': 'id'},\n","    'record_id': {'sdtype': 'id'},\n","    'employee_id': {'sdtype': 'id'},\n","    'report_type': {'sdtype': 'categorical'},\n","    'report_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'findings': {'sdtype': 'categorical'},\n","    'recommendations': {'sdtype': 'categorical'},\n","    'urgency_level': {'sdtype': 'categorical'},\n","    'is_abnormal': {'sdtype': 'categorical'},\n","    'cost': {'sdtype': 'numerical'}}},\n","  'prescriptions': {'primary_key': 'prescription_id',\n","   'columns': {'prescription_id': {'sdtype': 'id'},\n","    'record_id': {'sdtype': 'id'},\n","    'product_id': {'sdtype': 'id'},\n","    'prescribing_doctor': {'sdtype': 'numerical'},\n","    'prescription_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'dosage': {'sdtype': 'categorical'},\n","    'quantity_prescribed': {'sdtype': 'numerical'},\n","    'refills_remaining': {'sdtype': 'categorical'},\n","    'expiry_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'is_filled': {'sdtype': 'categorical'},\n","    'pharmacy_notes': {'sdtype': 'categorical'}}},\n","  'appointments': {'primary_key': 'appointment_id',\n","   'columns': {'appointment_id': {'sdtype': 'id'},\n","    'customer_id': {'sdtype': 'id'},\n","    'employee_id': {'sdtype': 'id'},\n","    'location_id': {'sdtype': 'id'},\n","    'appointment_date': {'sdtype': 'datetime'},\n","    'appointment_type': {'sdtype': 'categorical'},\n","    'status': {'sdtype': 'categorical'},\n","    'duration_minutes': {'sdtype': 'categorical'},\n","    'reason': {'sdtype': 'categorical'},\n","    'notes': {'sdtype': 'categorical'}}},\n","  'insurance_policies': {'primary_key': 'policy_id',\n","   'columns': {'policy_id': {'sdtype': 'id'},\n","    'customer_id': {'sdtype': 'id'},\n","    'policy_number': {'sdtype': 'categorical'},\n","    'insurance_company': {'sdtype': 'categorical'},\n","    'policy_type': {'sdtype': 'categorical'},\n","    'start_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'end_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'premium_amount': {'sdtype': 'numerical'},\n","    'deductible': {'sdtype': 'numerical'},\n","    'copay': {'sdtype': 'numerical'},\n","    'coverage_percent': {'sdtype': 'categorical'},\n","    'is_active': {'sdtype': 'categorical'}}},\n","  'claims': {'primary_key': 'claim_id',\n","   'columns': {'claim_id': {'sdtype': 'id'},\n","    'policy_id': {'sdtype': 'id'},\n","    'transaction_id': {'sdtype': 'id'},\n","    'claim_number': {'sdtype': 'categorical'},\n","    'claim_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'claim_amount': {'sdtype': 'numerical'},\n","    'approved_amount': {'sdtype': 'numerical'},\n","    'status': {'sdtype': 'categorical'},\n","    'denial_reason': {'sdtype': 'categorical'},\n","    'processing_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'}}},\n","  'inventory': {'primary_key': 'inventory_id',\n","   'columns': {'inventory_id': {'sdtype': 'id'},\n","    'product_id': {'sdtype': 'id'},\n","    'location_id': {'sdtype': 'id'},\n","    'supplier_id': {'sdtype': 'id'},\n","    'quantity_on_hand': {'sdtype': 'numerical'},\n","    'reorder_level': {'sdtype': 'numerical'},\n","    'max_stock_level': {'sdtype': 'numerical'},\n","    'last_restock_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'expiry_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'lot_number': {'sdtype': 'categorical'},\n","    'unit_cost': {'sdtype': 'numerical'},\n","    'storage_location': {'sdtype': 'categorical'}}},\n","  'reviews': {'primary_key': 'review_id',\n","   'columns': {'review_id': {'sdtype': 'id'},\n","    'customer_id': {'sdtype': 'id'},\n","    'product_id': {'sdtype': 'id'},\n","    'transaction_id': {'sdtype': 'id'},\n","    'rating': {'sdtype': 'categorical'},\n","    'review_text': {'sdtype': 'categorical'},\n","    'review_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'verified_purchase': {'sdtype': 'categorical'},\n","    'helpful_votes': {'sdtype': 'numerical'},\n","    'response_from_business': {'sdtype': 'categorical'}}},\n","  'loyalty_programs': {'primary_key': 'loyalty_id',\n","   'columns': {'loyalty_id': {'sdtype': 'id'},\n","    'customer_id': {'sdtype': 'id'},\n","    'program_name': {'sdtype': 'categorical'},\n","    'membership_level': {'sdtype': 'categorical'},\n","    'join_date': {'datetime_format': '%Y-%m-%d', 'sdtype': 'datetime'},\n","    'points_balance': {'sdtype': 'numerical'},\n","    'points_earned_total': {'sdtype': 'numerical'},\n","    'points_redeemed_total': {'sdtype': 'numerical'},\n","    'last_activity_date': {'datetime_format': '%Y-%m-%d',\n","     'sdtype': 'datetime'},\n","    'is_active': {'sdtype': 'categorical'},\n","    'annual_spending': {'sdtype': 'numerical'}}},\n","  'audit_logs': {'primary_key': 'log_id',\n","   'columns': {'log_id': {'sdtype': 'id'},\n","    'user_id': {'sdtype': 'id'},\n","    'action': {'sdtype': 'categorical'},\n","    'table_name': {'sdtype': 'categorical'},\n","    'record_id': {'sdtype': 'id'},\n","    'timestamp': {'sdtype': 'datetime'},\n","    'ip_address': {'pii': True, 'sdtype': 'ipv6_address'},\n","    'user_agent': {'pii': True, 'sdtype': 'user_agent_string'},\n","    'session_id': {'sdtype': 'id'},\n","    'details': {'sdtype': 'categorical'}}}},\n"," 'relationships': [],\n"," 'METADATA_SPEC_VERSION': 'V1'}"]},"metadata":{},"execution_count":10}],"source":["metadata_dict\n","\n","#Added table 'companies' with primary key 'company_id'\n","#Added table 'departments' with primary key 'dept_id'\n","#Added table 'locations' with primary key 'location_id'\n","#Added table 'employees' with primary key 'employee_id'\n","#Added table 'customers' with primary key 'customer_id'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1758276508101,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"-ZODnbKONI2t","outputId":"1d70cf9d-50dc-416d-d7ed-a8dcb3587686"},"outputs":[{"name":"stdout","output_type":"stream","text":["üîß ENHANCING AUTO-DETECTED RELATIONSHIPS\n","============================================================\n","üîó Adding critical relationships that may need manual specification...\n"," ===> NO relationship<=====\n","====> parent_table_name :   companies\n","====> parent_primary_key :   company_id\n","====> child_table_name :   departments\n","====> child_foreign_key :   company_id\n","‚ùå Error adding relationship: Unknown table name ('company_id').\n"," ===> NO relationship<=====\n","====> parent_table_name :   companies\n","====> parent_primary_key :   company_id\n","====> child_table_name :   locations\n","====> child_foreign_key :   company_id\n","‚ùå Error adding relationship: Unknown table name ('company_id').\n"," ===> NO relationship<=====\n","====> parent_table_name :   departments\n","====> parent_primary_key :   dept_id\n","====> child_table_name :   employees\n","====> child_foreign_key :   dept_id\n","‚ùå Error adding relationship: Unknown table name ('dept_id').\n"," ===> NO relationship<=====\n","====> parent_table_name :   locations\n","====> parent_primary_key :   location_id\n","====> child_table_name :   employees\n","====> child_foreign_key :   location_id\n","‚ùå Error adding relationship: Unknown table name ('location_id').\n"," ===> NO relationship<=====\n","‚ùå Error adding relationship: Column 'dept_id' not found in 'customers'\n"," ===> NO relationship<=====\n","‚ùå Error adding relationship: Column 'location_id' not found in 'customers'\n","\n","‚úÖ Added 6 additional relationships\n","\n","üìä FINAL RELATIONSHIP ANALYSIS:\n","\n","üîç ANALYZING RELATIONSHIP STRUCTURE\n","==================================================\n","üìä Total relationships detected: 0\n","üîÑ Self-referencing relationships: 0\n","üå≥ Hierarchical relationships: 0\n","   üîó Total relationships: 0\n","   üå≥ Hierarchical: 0\n","   üîÑ Self-referencing: 0\n","\n","üé® Creating comprehensive relationship visualization...\n"]}],"source":["print(\"üîß ENHANCING AUTO-DETECTED RELATIONSHIPS\")\n","print(\"=\" * 60)\n","\n","# Add any missing relationships that auto-detection might have missed\n","print(\"üîó Adding critical relationships that may need manual specification...\")\n","\n","# Key business relationships that must be explicitly defined\n","critical_relationships = [\n","    # Company hierarchy\n","    ('companies', 'company_id', 'departments', 'company_id'),\n","    ('companies', 'company_id', 'locations', 'company_id'),\n","\n","    # Employee relationships\n","    ('departments', 'dept_id', 'employees', 'dept_id'),\n","    ('locations', 'location_id', 'employees', 'location_id'),\n","\n","    # Customer relationships\n","    ('departments', 'dept_id', 'customers', 'dept_id'),\n","    ('locations', 'location_id', 'customers', 'location_id')\n","]\n","\n","# Add relationships that weren't auto-detected\n","added_relationships = 0\n","for parent_table, parent_col, child_table, child_col in critical_relationships:\n","    try:\n","        # Check if relationship already exists\n","        existing_rels = synthesizer.metadata.to_dict().get('relationships', [])\n","        relationship_exists = any(\n","            rel.get('parent_table_name') == parent_table and\n","            rel.get('child_table_name') == child_table and\n","            rel.get('parent_primary_key') == parent_col and\n","            rel.get('child_foreign_key') == child_col\n","            for rel in existing_rels\n","        )\n","\n","        if not relationship_exists:\n","            print(\" ===> NO relationship<=====\")\n","            synthesizer.add_custom_relationship(parent_table, parent_col, child_table, child_col)\n","            added_relationships += 1\n","\n","    except Exception as e:\n","        print(f\"   ‚ö†Ô∏è Could not add {parent_table}.{parent_col} ‚Üí {child_table}.{child_col}: {e}\")\n","\n","print(f\"\\n‚úÖ Added {added_relationships} additional relationships\")\n","\n","# Re-analyze relationships after manual additions\n","print(f\"\\nüìä FINAL RELATIONSHIP ANALYSIS:\")\n","final_analysis = synthesizer.analyze_relationships()\n","\n","print(f\"   üîó Total relationships: {final_analysis.get('total_relationships', 0)}\")\n","print(f\"   üå≥ Hierarchical: {final_analysis.get('hierarchical', 0)}\")\n","print(f\"   üîÑ Self-referencing: {final_analysis.get('self_referencing', 0)}\")\n","\n","# Create relationship visualization\n","print(f\"\\nüé® Creating comprehensive relationship visualization...\")\n","#synthesizer.visualize_table_dependencies(figsize=(18, 12))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1758275946079,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"JmTENU39aY0t","outputId":"a40916d3-6618-45e0-837a-7b16dd6356e7"},"outputs":[{"data":{"text/plain":["{\n","    \"tables\": {\n","        \"companies\": {\n","            \"columns\": {\n","                \"company_id\": {\n","                    \"sdtype\": \"id\"\n","                },\n","                \"company_name\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"company_type\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"founded_year\": {\n","                    \"sdtype\": \"numerical\"\n","                },\n","                \"headquarters\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"annual_revenue\": {\n","                    \"sdtype\": \"numerical\"\n","                },\n","                \"employee_count\": {\n","                    \"sdtype\": \"numerical\"\n","                }\n","            },\n","            \"primary_key\": \"company_id\"\n","        },\n","        \"departments\": {\n","            \"columns\": {\n","                \"dept_id\": {\n","                    \"sdtype\": \"id\"\n","                },\n","                \"company_id\": {\n","                    \"sdtype\": \"id\"\n","                },\n","                \"dept_name\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"budget\": {\n","                    \"sdtype\": \"numerical\"\n","                },\n","                \"manager_name\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"location_floor\": {\n","                    \"sdtype\": \"numerical\"\n","                }\n","            },\n","            \"primary_key\": \"dept_id\"\n","        },\n","        \"locations\": {\n","            \"columns\": {\n","                \"location_id\": {\n","                    \"sdtype\": \"id\"\n","                },\n","                \"company_id\": {\n","                    \"sdtype\": \"id\"\n","                },\n","                \"location_name\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"address\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"city\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"city\"\n","                },\n","                \"state\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"administrative_unit\"\n","                },\n","                \"zip_code\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"postcode\"\n","                },\n","                \"phone\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"facility_type\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"square_feet\": {\n","                    \"sdtype\": \"numerical\"\n","                }\n","            },\n","            \"primary_key\": \"location_id\"\n","        },\n","        \"employees\": {\n","            \"columns\": {\n","                \"employee_id\": {\n","                    \"sdtype\": \"id\"\n","                },\n","                \"dept_id\": {\n","                    \"sdtype\": \"id\"\n","                },\n","                \"location_id\": {\n","                    \"sdtype\": \"id\"\n","                },\n","                \"first_name\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"first_name\"\n","                },\n","                \"last_name\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"last_name\"\n","                },\n","                \"email\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"email\"\n","                },\n","                \"phone\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"hire_date\": {\n","                    \"datetime_format\": \"%Y-%m-%d\",\n","                    \"sdtype\": \"datetime\"\n","                },\n","                \"salary\": {\n","                    \"sdtype\": \"numerical\"\n","                },\n","                \"position\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"employment_status\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"reports_to\": {\n","                    \"sdtype\": \"numerical\"\n","                }\n","            },\n","            \"primary_key\": \"employee_id\"\n","        },\n","        \"customers\": {\n","            \"columns\": {\n","                \"customer_id\": {\n","                    \"sdtype\": \"id\"\n","                },\n","                \"first_name\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"first_name\"\n","                },\n","                \"last_name\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"last_name\"\n","                },\n","                \"email\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"email\"\n","                },\n","                \"phone\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"date_of_birth\": {\n","                    \"datetime_format\": \"%Y-%m-%d\",\n","                    \"sdtype\": \"datetime\"\n","                },\n","                \"gender\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"address\": {\n","                    \"sdtype\": \"categorical\"\n","                },\n","                \"city\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"city\"\n","                },\n","                \"state\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"administrative_unit\"\n","                },\n","                \"zip_code\": {\n","                    \"pii\": true,\n","                    \"sdtype\": \"postcode\"\n","                },\n","                \"registration_date\": {\n","                    \"datetime_format\": \"%Y-%m-%d\",\n","                    \"sdtype\": \"datetime\"\n","                },\n","                \"customer_type\": {\n","                    \"sdtype\": \"categorical\"\n","                }\n","            },\n","            \"primary_key\": \"customer_id\"\n","        }\n","    },\n","    \"relationships\": [],\n","    \"METADATA_SPEC_VERSION\": \"V1\"\n","}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["synthesizer.metadata"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1758511124016,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"BC1eJ4mledlc"},"outputs":[],"source":["def add_relationships_from_list(\n","    metadata,\n","    rel_list,\n","    *,\n","    dependency_graph=None,   # must be passed by keyword\n","    strict=True,\n","    verbose=True,\n","):\n","    \"\"\"\n","    Add relationships to SDV MultiTable metadata from a list of 4-tuples:\n","      (parent_table, parent_primary_key, child_table, child_foreign_key)\n","    Works when metadata.tables items are dicts or SingleTableMetadata objects.\n","    \"\"\"\n","    results = {\"added\": [], \"skipped_existing\": [], \"skipped_invalid\": [], \"errors\": []}\n","\n","    # --- helpers -------------------------------------------------------------\n","    def _table_meta_to_dict(tbl_meta):\n","        if isinstance(tbl_meta, dict):\n","            pk = tbl_meta.get(\"primary_key\")\n","            cols = tbl_meta.get(\"fields\") or tbl_meta.get(\"columns\") or {}\n","            return {\"primary_key\": pk, \"columns\": cols}\n","        if hasattr(tbl_meta, \"to_dict\"):\n","            d = tbl_meta.to_dict()\n","            pk = d.get(\"primary_key\")\n","            cols = d.get(\"fields\") or d.get(\"columns\") or {}\n","            return {\"primary_key\": pk, \"columns\": cols}\n","        pk = getattr(tbl_meta, \"primary_key\", None)\n","        if hasattr(tbl_meta, \"get_columns\"):\n","            cols_dict = {c: {} for c in tbl_meta.get_columns()}\n","        else:\n","            cols_attr = getattr(tbl_meta, \"columns\", None)\n","            if isinstance(cols_attr, dict):\n","                cols_dict = cols_attr\n","            elif isinstance(cols_attr, (list, tuple)):\n","                cols_dict = {c: {} for c in cols_attr}\n","            else:\n","                cols_dict = {}\n","        return {\"primary_key\": pk, \"columns\": cols_dict}\n","\n","    def _relationship_exists(meta, ptab, ctab, ppk, cfk):\n","        rels = getattr(meta, \"relationships\", []) or []\n","        for r in rels:\n","            if isinstance(r, dict):\n","                if (r.get(\"parent_table_name\") == ptab and\n","                    r.get(\"child_table_name\") == ctab and\n","                    r.get(\"parent_primary_key\") == ppk and\n","                    r.get(\"child_foreign_key\") == cfk):\n","                    return True\n","            else:\n","                if (getattr(r, \"parent_table_name\", None) == ptab and\n","                    getattr(r, \"child_table_name\", None) == ctab and\n","                    getattr(r, \"parent_primary_key\", None) == ppk and\n","                    getattr(r, \"child_foreign_key\", None) == cfk):\n","                    return True\n","        return False\n","\n","    if not hasattr(metadata, \"tables\"):\n","        raise TypeError(\"Provided metadata has no 'tables' attribute. Need MultiTable metadata.\")\n","\n","    tables = metadata.tables\n","\n","    for rel in rel_list:\n","        try:\n","            if len(rel) != 4:\n","                msg = \"tuple must be (parent_table, parent_pk, child_table, child_fk)\"\n","                if strict: raise ValueError(msg)\n","                results[\"skipped_invalid\"].append((rel, msg))\n","                if verbose: print(f\"‚ö†Ô∏è {msg}: {rel}\")\n","                continue\n","\n","            parent_table, parent_pk, child_table, child_fk = rel\n","\n","            if parent_table not in tables:\n","                msg = f\"parent table '{parent_table}' not found\"\n","                if strict: raise KeyError(msg)\n","                results[\"skipped_invalid\"].append((rel, msg))\n","                if verbose: print(f\"‚ö†Ô∏è {msg}\")\n","                continue\n","\n","            if child_table not in tables:\n","                msg = f\"child table '{child_table}' not found\"\n","                if strict: raise KeyError(msg)\n","                results[\"skipped_invalid\"].append((rel, msg))\n","                if verbose: print(f\"‚ö†Ô∏è {msg}\")\n","                continue\n","\n","            pinfo = _table_meta_to_dict(tables[parent_table])\n","            cinfo = _table_meta_to_dict(tables[child_table])\n","\n","            declared_pk = pinfo.get(\"primary_key\")\n","            if declared_pk and declared_pk != parent_pk:\n","                msg = (f\"declared primary key for '{parent_table}' is '{declared_pk}', not '{parent_pk}'\")\n","                if strict: raise ValueError(msg)\n","                if verbose: print(f\"‚ö†Ô∏è {msg}. Proceeding anyway.\")\n","\n","            child_cols = cinfo.get(\"columns\") or {}\n","            if child_fk not in child_cols:\n","                msg = f\"child foreign key '{child_fk}' not found in '{child_table}'\"\n","                if strict: raise KeyError(msg)\n","                results[\"skipped_invalid\"].append((rel, msg))\n","                if verbose: print(f\"‚ö†Ô∏è {msg}\")\n","                continue\n","\n","            if _relationship_exists(metadata, parent_table, child_table, parent_pk, child_fk):\n","                results[\"skipped_existing\"].append(rel)\n","                if verbose: print(f\"‚è≠Ô∏è Already exists: {rel}\")\n","                # still mirror into graph if provided\n","                if dependency_graph is not None and hasattr(dependency_graph, \"add_edge\"):\n","                    dependency_graph.add_edge(parent_table, child_table)\n","                continue\n","\n","            # Add to SDV metadata\n","            metadata.add_relationship(\n","                parent_table_name=parent_table,\n","                child_table_name=child_table,\n","                parent_primary_key=parent_pk,\n","                child_foreign_key=child_fk\n","            )\n","\n","            # Add to dependency graph (optional)\n","            if dependency_graph is not None and hasattr(dependency_graph, \"add_edge\"):\n","                dependency_graph.add_edge(parent_table, child_table)\n","\n","            results[\"added\"].append(rel)\n","            if verbose: print(f\"‚úÖ Added: {parent_table}.{parent_pk} ‚Üí {child_table}.{child_fk}\")\n","\n","        except Exception as e:\n","            results[\"errors\"].append((rel, str(e)))\n","            if verbose: print(f\"‚ùå Error adding {rel}: {e}\")\n","\n","    return results\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1758511129373,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"lv79Sey-ehj4","outputId":"cfe50f21-0e67-4b02-bdba-c71bb672b173"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Added: companies.company_id ‚Üí departments.company_id\n","‚úÖ Added: companies.company_id ‚Üí locations.company_id\n","‚úÖ Added: departments.dept_id ‚Üí employees.dept_id\n","‚úÖ Added: locations.location_id ‚Üí employees.location_id\n","‚ùå Error adding ('employees', 'employee_id', 'employees', 'reports_to'): Relationship between tables ('employees', 'employees') is invalid. The primary and foreign key columns are not the same type.\n","‚ùå Error adding ('categories', 'category_id', 'categories', 'parent_category_id'): The relationships in the dataset describe a circular dependency between tables ['categories', 'categories'].\n","‚úÖ Added: customers.customer_id ‚Üí transactions.customer_id\n","‚úÖ Added: customers.customer_id ‚Üí medical_records.customer_id\n","‚úÖ Added: customers.customer_id ‚Üí appointments.customer_id\n","‚úÖ Added: customers.customer_id ‚Üí insurance_policies.customer_id\n","‚úÖ Added: customers.customer_id ‚Üí loyalty_programs.customer_id\n","‚úÖ Added: categories.category_id ‚Üí products.category_id\n","‚úÖ Added: products.product_id ‚Üí transaction_items.product_id\n","‚úÖ Added: products.product_id ‚Üí inventory.product_id\n","‚úÖ Added: products.product_id ‚Üí reviews.product_id\n","‚úÖ Added: products.product_id ‚Üí prescriptions.product_id\n","‚úÖ Added: transactions.transaction_id ‚Üí transaction_items.transaction_id\n","‚úÖ Added: transactions.transaction_id ‚Üí claims.transaction_id\n","‚úÖ Added: transactions.transaction_id ‚Üí reviews.transaction_id\n","‚úÖ Added: employees.employee_id ‚Üí transactions.employee_id\n","‚úÖ Added: locations.location_id ‚Üí transactions.location_id\n","‚úÖ Added: medical_records.record_id ‚Üí medical_reports.record_id\n","‚úÖ Added: medical_records.record_id ‚Üí prescriptions.record_id\n","‚úÖ Added: employees.employee_id ‚Üí medical_records.employee_id\n","‚úÖ Added: employees.employee_id ‚Üí appointments.employee_id\n","‚úÖ Added: locations.location_id ‚Üí medical_records.location_id\n","‚úÖ Added: locations.location_id ‚Üí appointments.location_id\n","‚úÖ Added: insurance_policies.policy_id ‚Üí claims.policy_id\n","‚úÖ Added: suppliers.supplier_id ‚Üí inventory.supplier_id\n","‚úÖ Added: locations.location_id ‚Üí inventory.location_id\n","‚úÖ Added: employees.employee_id ‚Üí audit_logs.user_id\n","{'added': [('companies', 'company_id', 'departments', 'company_id'), ('companies', 'company_id', 'locations', 'company_id'), ('departments', 'dept_id', 'employees', 'dept_id'), ('locations', 'location_id', 'employees', 'location_id'), ('customers', 'customer_id', 'transactions', 'customer_id'), ('customers', 'customer_id', 'medical_records', 'customer_id'), ('customers', 'customer_id', 'appointments', 'customer_id'), ('customers', 'customer_id', 'insurance_policies', 'customer_id'), ('customers', 'customer_id', 'loyalty_programs', 'customer_id'), ('categories', 'category_id', 'products', 'category_id'), ('products', 'product_id', 'transaction_items', 'product_id'), ('products', 'product_id', 'inventory', 'product_id'), ('products', 'product_id', 'reviews', 'product_id'), ('products', 'product_id', 'prescriptions', 'product_id'), ('transactions', 'transaction_id', 'transaction_items', 'transaction_id'), ('transactions', 'transaction_id', 'claims', 'transaction_id'), ('transactions', 'transaction_id', 'reviews', 'transaction_id'), ('employees', 'employee_id', 'transactions', 'employee_id'), ('locations', 'location_id', 'transactions', 'location_id'), ('medical_records', 'record_id', 'medical_reports', 'record_id'), ('medical_records', 'record_id', 'prescriptions', 'record_id'), ('employees', 'employee_id', 'medical_records', 'employee_id'), ('employees', 'employee_id', 'appointments', 'employee_id'), ('locations', 'location_id', 'medical_records', 'location_id'), ('locations', 'location_id', 'appointments', 'location_id'), ('insurance_policies', 'policy_id', 'claims', 'policy_id'), ('suppliers', 'supplier_id', 'inventory', 'supplier_id'), ('locations', 'location_id', 'inventory', 'location_id'), ('employees', 'employee_id', 'audit_logs', 'user_id')], 'skipped_existing': [], 'skipped_invalid': [], 'errors': [(('employees', 'employee_id', 'employees', 'reports_to'), \"Relationship between tables ('employees', 'employees') is invalid. The primary and foreign key columns are not the same type.\"), (('categories', 'category_id', 'categories', 'parent_category_id'), \"The relationships in the dataset describe a circular dependency between tables ['categories', 'categories'].\")]}\n"]}],"source":["critical_relationships = [\n","    # Company hierarchy\n","    ('companies', 'company_id', 'departments', 'company_id'),\n","    ('companies', 'company_id', 'locations', 'company_id'),\n","\n","    # Employee relationships\n","    ('departments', 'dept_id', 'employees', 'dept_id'),\n","    ('locations', 'location_id', 'employees', 'location_id'),\n","\n","    # Self-referencing relationships\n","    ('employees', 'employee_id', 'employees', 'reports_to'),\n","    ('categories', 'category_id', 'categories', 'parent_category_id'),\n","\n","    # Customer relationships\n","    ('customers', 'customer_id', 'transactions', 'customer_id'),\n","    ('customers', 'customer_id', 'medical_records', 'customer_id'),\n","    ('customers', 'customer_id', 'appointments', 'customer_id'),\n","    ('customers', 'customer_id', 'insurance_policies', 'customer_id'),\n","    ('customers', 'customer_id', 'loyalty_programs', 'customer_id'),\n","\n","    # Product and inventory relationships\n","    ('categories', 'category_id', 'products', 'category_id'),\n","    ('products', 'product_id', 'transaction_items', 'product_id'),\n","    ('products', 'product_id', 'inventory', 'product_id'),\n","    ('products', 'product_id', 'reviews', 'product_id'),\n","    ('products', 'product_id', 'prescriptions', 'product_id'),\n","\n","    # Transaction relationships\n","    ('transactions', 'transaction_id', 'transaction_items', 'transaction_id'),\n","    ('transactions', 'transaction_id', 'claims', 'transaction_id'),\n","    ('transactions', 'transaction_id', 'reviews', 'transaction_id'),\n","    ('employees', 'employee_id', 'transactions', 'employee_id'),\n","    ('locations', 'location_id', 'transactions', 'location_id'),\n","\n","    # Medical relationships\n","    ('medical_records', 'record_id', 'medical_reports', 'record_id'),\n","    ('medical_records', 'record_id', 'prescriptions', 'record_id'),\n","    ('employees', 'employee_id', 'medical_records', 'employee_id'),\n","    ('employees', 'employee_id', 'appointments', 'employee_id'),\n","    ('locations', 'location_id', 'medical_records', 'location_id'),\n","    ('locations', 'location_id', 'appointments', 'location_id'),\n","\n","    # Insurance relationships\n","    ('insurance_policies', 'policy_id', 'claims', 'policy_id'),\n","\n","    # Supplier and inventory\n","    ('suppliers', 'supplier_id', 'inventory', 'supplier_id'),\n","    ('locations', 'location_id', 'inventory', 'location_id'),\n","\n","    # Audit trail\n","    ('employees', 'employee_id', 'audit_logs', 'user_id')\n","]\n","\n","mData = synthesizer.metadata  # must be MultiTable metadata\n","graph = synthesizer.dependency_graph\n","\n","summary = add_relationships_from_list(\n","    mData,\n","    critical_relationships,\n","    dependency_graph=graph,    # <-- pass by keyword\n","    strict=False,\n","    verbose=True\n",")\n","print(summary)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62,"status":"ok","timestamp":1758511147170,"user":{"displayName":"Lakshminarayana Naidu","userId":"02129415072663551429"},"user_tz":-480},"id":"Iwn0GHYHfemv","outputId":"17e42b09-e35a-491c-a562-977e6eeb3af1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'parent_table_name': 'companies',\n","  'child_table_name': 'departments',\n","  'parent_primary_key': 'company_id',\n","  'child_foreign_key': 'company_id'},\n"," {'parent_table_name': 'companies',\n","  'child_table_name': 'locations',\n","  'parent_primary_key': 'company_id',\n","  'child_foreign_key': 'company_id'},\n"," {'parent_table_name': 'departments',\n","  'child_table_name': 'employees',\n","  'parent_primary_key': 'dept_id',\n","  'child_foreign_key': 'dept_id'},\n"," {'parent_table_name': 'locations',\n","  'child_table_name': 'employees',\n","  'parent_primary_key': 'location_id',\n","  'child_foreign_key': 'location_id'},\n"," {'parent_table_name': 'customers',\n","  'child_table_name': 'transactions',\n","  'parent_primary_key': 'customer_id',\n","  'child_foreign_key': 'customer_id'},\n"," {'parent_table_name': 'customers',\n","  'child_table_name': 'medical_records',\n","  'parent_primary_key': 'customer_id',\n","  'child_foreign_key': 'customer_id'},\n"," {'parent_table_name': 'customers',\n","  'child_table_name': 'appointments',\n","  'parent_primary_key': 'customer_id',\n","  'child_foreign_key': 'customer_id'},\n"," {'parent_table_name': 'customers',\n","  'child_table_name': 'insurance_policies',\n","  'parent_primary_key': 'customer_id',\n","  'child_foreign_key': 'customer_id'},\n"," {'parent_table_name': 'customers',\n","  'child_table_name': 'loyalty_programs',\n","  'parent_primary_key': 'customer_id',\n","  'child_foreign_key': 'customer_id'},\n"," {'parent_table_name': 'categories',\n","  'child_table_name': 'products',\n","  'parent_primary_key': 'category_id',\n","  'child_foreign_key': 'category_id'},\n"," {'parent_table_name': 'products',\n","  'child_table_name': 'transaction_items',\n","  'parent_primary_key': 'product_id',\n","  'child_foreign_key': 'product_id'},\n"," {'parent_table_name': 'products',\n","  'child_table_name': 'inventory',\n","  'parent_primary_key': 'product_id',\n","  'child_foreign_key': 'product_id'},\n"," {'parent_table_name': 'products',\n","  'child_table_name': 'reviews',\n","  'parent_primary_key': 'product_id',\n","  'child_foreign_key': 'product_id'},\n"," {'parent_table_name': 'products',\n","  'child_table_name': 'prescriptions',\n","  'parent_primary_key': 'product_id',\n","  'child_foreign_key': 'product_id'},\n"," {'parent_table_name': 'transactions',\n","  'child_table_name': 'transaction_items',\n","  'parent_primary_key': 'transaction_id',\n","  'child_foreign_key': 'transaction_id'},\n"," {'parent_table_name': 'transactions',\n","  'child_table_name': 'claims',\n","  'parent_primary_key': 'transaction_id',\n","  'child_foreign_key': 'transaction_id'},\n"," {'parent_table_name': 'transactions',\n","  'child_table_name': 'reviews',\n","  'parent_primary_key': 'transaction_id',\n","  'child_foreign_key': 'transaction_id'},\n"," {'parent_table_name': 'employees',\n","  'child_table_name': 'transactions',\n","  'parent_primary_key': 'employee_id',\n","  'child_foreign_key': 'employee_id'},\n"," {'parent_table_name': 'locations',\n","  'child_table_name': 'transactions',\n","  'parent_primary_key': 'location_id',\n","  'child_foreign_key': 'location_id'},\n"," {'parent_table_name': 'medical_records',\n","  'child_table_name': 'medical_reports',\n","  'parent_primary_key': 'record_id',\n","  'child_foreign_key': 'record_id'},\n"," {'parent_table_name': 'medical_records',\n","  'child_table_name': 'prescriptions',\n","  'parent_primary_key': 'record_id',\n","  'child_foreign_key': 'record_id'},\n"," {'parent_table_name': 'employees',\n","  'child_table_name': 'medical_records',\n","  'parent_primary_key': 'employee_id',\n","  'child_foreign_key': 'employee_id'},\n"," {'parent_table_name': 'employees',\n","  'child_table_name': 'appointments',\n","  'parent_primary_key': 'employee_id',\n","  'child_foreign_key': 'employee_id'},\n"," {'parent_table_name': 'locations',\n","  'child_table_name': 'medical_records',\n","  'parent_primary_key': 'location_id',\n","  'child_foreign_key': 'location_id'},\n"," {'parent_table_name': 'locations',\n","  'child_table_name': 'appointments',\n","  'parent_primary_key': 'location_id',\n","  'child_foreign_key': 'location_id'},\n"," {'parent_table_name': 'insurance_policies',\n","  'child_table_name': 'claims',\n","  'parent_primary_key': 'policy_id',\n","  'child_foreign_key': 'policy_id'},\n"," {'parent_table_name': 'suppliers',\n","  'child_table_name': 'inventory',\n","  'parent_primary_key': 'supplier_id',\n","  'child_foreign_key': 'supplier_id'},\n"," {'parent_table_name': 'locations',\n","  'child_table_name': 'inventory',\n","  'parent_primary_key': 'location_id',\n","  'child_foreign_key': 'location_id'},\n"," {'parent_table_name': 'employees',\n","  'child_table_name': 'audit_logs',\n","  'parent_primary_key': 'employee_id',\n","  'child_foreign_key': 'user_id'}]"]},"metadata":{},"execution_count":13}],"source":["synthesizer.metadata.relationships"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HooYpzU1NI5P","outputId":"0eb921bf-82f8-48eb-8394-14396eadf62c"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üöÄ TRAINING MULTI-TABLE SYNTHESIZER\n","============================================================\n","üìä PRE-TRAINING SUMMARY:\n","   üìã Tables to train on: 20\n","   üìà Total training records: 19,115\n","   üîó Total relationships: 29\n","   üíæ Dataset memory usage: 6.40 MB\n","\n","üöÄ TRAINING MULTI-TABLE SYNTHESIZER\n","==================================================\n","üîç Validating metadata structure...\n","‚úÖ Metadata validation successful\n","ü§ñ Initializing gaussian_copula synthesizer...\n","PerformanceAlert: Using the HMASynthesizer on this metadata schema is not recommended. To model this data, HMA will generate a large number of columns. (27393830626741628 columns)\n","\n","\n","        Table Name  # Columns in Metadata     Est # Columns\n","         companies                      6 27393830295659408\n","       departments                      4         165501720\n","         locations                      8         165519905\n","         employees                      9             18190\n","         customers                     12             20216\n","        categories                      4             21527\n","          products                      9               204\n","         suppliers                     10                71\n","      transactions                      8               131\n"," transaction_items                      4                 4\n","   medical_records                      9               131\n","   medical_reports                      8                 8\n","     prescriptions                      8                 8\n","      appointments                      6                 6\n","insurance_policies                     10                60\n","            claims                      7                 7\n","         inventory                      8                 8\n","           reviews                      7                 7\n","  loyalty_programs                      9                 9\n","        audit_logs                      8                 8\n","\n","We recommend simplifying your metadata schema using 'sdv.utils.poc.simplify_schema'.\n","If this is not possible, please visit datacebo.com and reach out to us for enterprise solutions.\n","\n","‚úÖ Synthesizer initialized successfully\n","üìö Starting training process...\n","   üìä Training on 20 tables\n","   üìà Total data points: 19,115\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Preprocess Tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:08<00:00,  2.45it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Learning relationships:\n"]},{"output_type":"stream","name":"stderr","text":["(1/29) Tables 'transactions' and 'transaction_items' ('transaction_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1837/1837 [05:19<00:00,  5.74it/s]\n","(2/29) Tables 'transactions' and 'reviews' ('transaction_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1054/1054 [02:01<00:00,  8.70it/s]\n","(3/29) Tables 'transactions' and 'claims' ('transaction_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 284/284 [00:07<00:00, 36.15it/s]\n","(4/29) Tables 'locations' and 'transactions' ('location_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:17<00:00,  1.18s/it]\n","(5/29) Tables 'locations' and 'inventory' ('location_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:06<00:00,  2.27it/s]\n","(6/29) Tables 'employees' and 'transactions' ('employee_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [03:23<00:00,  1.02s/it]\n","(7/29) Tables 'employees' and 'appointments' ('employee_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [01:07<00:00,  2.97it/s]\n","(8/29) Tables 'employees' and 'audit_logs' ('user_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [01:08<00:00,  2.90it/s]\n","(9/29) Tables 'medical_records' and 'medical_reports' ('record_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320/320 [00:29<00:00, 10.96it/s]\n","(10/29) Tables 'medical_records' and 'prescriptions' ('record_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 413/413 [00:54<00:00,  7.54it/s]\n","(11/29) Tables 'employees' and 'medical_records' ('employee_id'): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 195/195 [02:57<00:00,  1.10it/s]\n","(12/29) Tables 'locations' and 'employees' ('location_id'):   0%|          | 0/15 [00:00<?, ?it/s]"]}],"source":["print(\"üöÄ TRAINING MULTI-TABLE SYNTHESIZER\")\n","print(\"=\" * 60)\n","\n","# Display pre-training summary\n","print(\"üìä PRE-TRAINING SUMMARY:\")\n","print(f\"   üìã Tables to train on: {len(enterprise_data)}\")\n","print(f\"   üìà Total training records: {sum(len(df) for df in enterprise_data.values()):,}\")\n","print(f\"   üîó Total relationships: {len(synthesizer.metadata.to_dict().get('relationships', []))}\")\n","print(f\"   üíæ Dataset memory usage: {sum(df.memory_usage(deep=True).sum() for df in enterprise_data.values()) / 1024 / 1024:.2f} MB\")\n","\n","# Start training with comprehensive monitoring\n","training_success = synthesizer.train_synthesizer(verbose=True)\n","\n","if training_success:\n","    print(\"\\nüéâ TRAINING COMPLETED SUCCESSFULLY!\")\n","\n","    # Display training statistics\n","    training_duration = synthesizer.generation_stats.get('training_duration', 0)\n","    print(f\"\\nüìä TRAINING PERFORMANCE METRICS:\")\n","    print(f\"   ‚è±Ô∏è  Total training time: {training_duration:.2f} seconds\")\n","    print(f\"   üìà Records per second: {sum(len(df) for df in enterprise_data.values()) / max(training_duration, 1):.0f}\")\n","    print(f\"   üß† Model complexity: Multi-table HMA with {len(enterprise_data)} tables\")\n","\n","    # Memory usage after training\n","    import psutil\n","    import os\n","\n","    try:\n","        process = psutil.Process(os.getpid())\n","        memory_usage = process.memory_info().rss / 1024 / 1024  # MB\n","        print(f\"   üíæ Current memory usage: {memory_usage:.2f} MB\")\n","    except:\n","        print(\"   üíæ Memory usage: Unable to determine\")\n","\n","    print(f\"\\n‚úÖ Synthesizer is ready for data generation!\")\n","\n","else:\n","    print(\"\\n‚ùå TRAINING FAILED!\")\n","    print(\"Please check the error messages above and verify your data structure.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBH37KnONI7j"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcm8X98MKXTALLgWW30hac"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}